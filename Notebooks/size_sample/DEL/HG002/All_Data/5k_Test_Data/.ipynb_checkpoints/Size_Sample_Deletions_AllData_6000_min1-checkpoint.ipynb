{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data: Consensus Genotype\n",
    "Size_Sample_Insertions_AllData_6000\n",
    "\n",
    "* Size Ranges\n",
    "* Training Dataset size : 6000\n",
    "* Predict minus 2 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import io\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import plotly.plotly as py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "from bokeh.charts import TimeSeries\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.charts import Scatter, Histogram, output_file, show\n",
    "from bokeh.plotting import figure, show, output_file, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "import bokeh.palettes as palettes\n",
    "from bokeh.models import HoverTool, BoxSelectTool, Legend\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Training Set\n",
    "\n",
    "Count : 6000\n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTconflict</th>\n",
       "      <th>GTcons</th>\n",
       "      <th>GTsupp</th>\n",
       "      <th>Ill250.GT</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>sample</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HG002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Insertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTconflict  GTcons  GTsupp  Ill250.GT  Ill250.alt_alnScore_mean  \\\n",
       "0          -1       2       2        2.0                958.307692   \n",
       "\n",
       "   Ill250.alt_alnScore_std  Ill250.alt_count  Ill250.alt_insertSize_mean  \\\n",
       "0                17.827742              52.0                  403.673077   \n",
       "\n",
       "   Ill250.alt_insertSize_std  Ill250.alt_reason_alignmentScore    ...      \\\n",
       "0                  79.999452                              52.0    ...       \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  sample  segdup_cnt  \\\n",
       "0                               0.0         0         0   HG002           0   \n",
       "\n",
       "   segdup_pct   start  tandemrep_cnt  tandemrep_pct       type  \n",
       "0         0.0  919991              1            1.0  Insertion  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Training Data\n",
    "# SVanalyzer generated training data\n",
    "df_train = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/train/6k.INS.test.csv')\n",
    "df_train_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/train/6k.INS.test.csv')\n",
    "df_train.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame()\n",
    "train_set = df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "train_set['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "train_set['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Count of Labels in Training Set **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heterozygous_Variant    1378\n",
       "Homozygous_Reference     790\n",
       "Homozygous_Variant      1014\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_set['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Test Set\n",
    "\n",
    "Count : 893\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hom_ref'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3268, 188)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Test Data\n",
    "# SVanalyzer generated training data\n",
    "df_test = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/test/5k.INS.test.csv')\n",
    "df_test_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/test/5k.INS.test.csv')\n",
    "df_test.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header names in lists and find names that are NOT contained in BOTH lists\n",
    "c = list(df_train.columns.values)\n",
    "d = list(df_test.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_train.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_train.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_train.drop(['sample'], axis=1, inplace = True)\n",
    "df_train.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_train.drop(['type'], axis=1, inplace = True)\n",
    "df_train.drop(['id'], axis=1, inplace = True)\n",
    "df_train.drop(['New_ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       2                958.307692                17.827742   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0         0         0           0   \n",
       "\n",
       "   segdup_pct   start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991              1            1.0  \n",
       "\n",
       "[1 rows x 176 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['chrom'].replace('X', 23, inplace=True)\n",
    "df_train['chrom'].replace('Y', 24, inplace=True)\n",
    "df_test['chrom'].replace('X', 23, inplace=True)\n",
    "df_test['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GTconflict',\n",
       " 'GTsupp',\n",
       " 'Ill250.GT',\n",
       " 'Ill300x.GT',\n",
       " 'IllMP.GT',\n",
       " 'New_ID',\n",
       " 'SVtype',\n",
       " 'TenX.GT',\n",
       " 'id',\n",
       " 'pacbio.GT',\n",
       " 'sample',\n",
       " 'type'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header names in lists and find names that are NOT contained in BOTH lists\n",
    "c = list(df_train.columns.values)\n",
    "d = list(df_test.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_test.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_test.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_test.drop(['sample'], axis=1, inplace = True)\n",
    "df_test.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_test.drop(['type'], axis=1, inplace = True)\n",
    "df_test.drop(['id'], axis=1, inplace = True)\n",
    "df_test.drop(['New_ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Import '-1' Labeled Data (Unknown Data) \n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Test Data\n",
    "# SVanalyzer generated training data\n",
    "df_min1 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/min1_DFs/INS/ins_HG002_min1.csv')\n",
    "df_min1_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/min1_DFs/INS/ins_HG002_min1.csv')\n",
    "df_min1.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_min1.drop(['New_ID'], axis=1, inplace = True)\n",
    "df_min1.drop(['index'], axis=1, inplace = True)\n",
    "df_min1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_min1['chrom'].replace('X', 23, inplace=True)\n",
    "df_min1['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_min1.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_min1.drop(['TenX.HP1_amb_reason_insertSizeScore_alignmentScore'], axis=1, inplace = True)\n",
    "df_min1.drop(['TenX.HP2_amb_reason_insertSizeScore_alignmentScore'], axis=1, inplace = True)\n",
    "df_min1.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_min1.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_min1.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_min1.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_min1.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_min1.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_min1.drop(['sample'], axis=1, inplace = True)\n",
    "df_min1.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_min1.drop(['type'], axis=1, inplace = True)\n",
    "df_min1.drop(['id'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Impute missing values using KNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>962.019608</td>\n",
       "      <td>14.772112</td>\n",
       "      <td>51.0</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>81.200068</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.634831</td>\n",
       "      <td>146.493457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>920006</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       2                958.307692                17.827742   \n",
       "1       2                958.307692                17.827742   \n",
       "2       2                962.019608                14.772112   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "1              52.0                  403.673077                  79.999452   \n",
       "2              51.0                  415.000000                  81.200068   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "1                              52.0                            0.0   \n",
       "2                              51.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "1                867.666667               144.039804      ...         \n",
       "2                866.634831               146.493457      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0         0         0           0   \n",
       "1                               0.0         0         0           0   \n",
       "2                               0.0         0         0           0   \n",
       "\n",
       "   segdup_pct   start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991              1            1.0  \n",
       "1         0.0  919991              1            1.0  \n",
       "2         0.0  920006              1            1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training data in a new variable which will be converted to a matrix\n",
    "X = df_train\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/3182 with 0 missing, elapsed time: 9.232\n",
      "Imputing row 101/3182 with 0 missing, elapsed time: 9.232\n",
      "Imputing row 201/3182 with 0 missing, elapsed time: 9.242\n",
      "Imputing row 301/3182 with 0 missing, elapsed time: 9.246\n",
      "Imputing row 401/3182 with 0 missing, elapsed time: 9.254\n",
      "Imputing row 501/3182 with 0 missing, elapsed time: 9.256\n",
      "Imputing row 601/3182 with 0 missing, elapsed time: 9.257\n",
      "Imputing row 701/3182 with 4 missing, elapsed time: 9.307\n",
      "Imputing row 801/3182 with 4 missing, elapsed time: 9.327\n",
      "Imputing row 901/3182 with 4 missing, elapsed time: 9.348\n",
      "Imputing row 1001/3182 with 4 missing, elapsed time: 9.370\n",
      "Imputing row 1101/3182 with 4 missing, elapsed time: 9.388\n",
      "Imputing row 1201/3182 with 59 missing, elapsed time: 9.426\n",
      "Imputing row 1301/3182 with 6 missing, elapsed time: 9.474\n",
      "Imputing row 1401/3182 with 6 missing, elapsed time: 9.507\n",
      "Imputing row 1501/3182 with 6 missing, elapsed time: 9.536\n",
      "Imputing row 1601/3182 with 6 missing, elapsed time: 9.565\n",
      "Imputing row 1701/3182 with 6 missing, elapsed time: 9.592\n",
      "Imputing row 1801/3182 with 60 missing, elapsed time: 9.624\n",
      "Imputing row 1901/3182 with 1 missing, elapsed time: 9.674\n",
      "Imputing row 2001/3182 with 1 missing, elapsed time: 9.685\n",
      "Imputing row 2101/3182 with 1 missing, elapsed time: 9.698\n",
      "Imputing row 2201/3182 with 1 missing, elapsed time: 9.704\n",
      "Imputing row 2301/3182 with 1 missing, elapsed time: 9.713\n",
      "Imputing row 2401/3182 with 1 missing, elapsed time: 9.723\n",
      "Imputing row 2501/3182 with 1 missing, elapsed time: 9.732\n",
      "Imputing row 2601/3182 with 2 missing, elapsed time: 9.788\n",
      "Imputing row 2701/3182 with 2 missing, elapsed time: 9.798\n",
      "Imputing row 2801/3182 with 2 missing, elapsed time: 9.808\n",
      "Imputing row 2901/3182 with 2 missing, elapsed time: 9.820\n",
      "Imputing row 3001/3182 with 2 missing, elapsed time: 9.831\n",
      "Imputing row 3101/3182 with 2 missing, elapsed time: 9.841\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "X=X.as_matrix()\n",
    "\n",
    "#Imput missing values from three closest observations\n",
    "X_imputed=KNN(k=3).complete(X)\n",
    "X=pd.DataFrame(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>962.019608</td>\n",
       "      <td>14.772112</td>\n",
       "      <td>51.0</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>81.200068</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.634831</td>\n",
       "      <td>146.493457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>920006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0     2.0                958.307692                17.827742   \n",
       "1     2.0                958.307692                17.827742   \n",
       "2     2.0                962.019608                14.772112   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "1              52.0                  403.673077                  79.999452   \n",
       "2              51.0                  415.000000                  81.200068   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "1                              52.0                            0.0   \n",
       "2                              51.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "1                867.666667               144.039804      ...         \n",
       "2                866.634831               146.493457      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0       0.0       0.0         0.0   \n",
       "1                               0.0       0.0       0.0         0.0   \n",
       "2                               0.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct     start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991.0            1.0            1.0  \n",
       "1         0.0  919991.0            1.0            1.0  \n",
       "2         0.0  920006.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header values in a list, will be used later to re-label the matrix post KNN imputation\n",
    "dftrain_header = list(df_train.columns.values)\n",
    "X.columns = dftrain_header\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Labels in a new 'Y' DataFrame\n",
    "Y = pd.DataFrame()\n",
    "Y = X['GTcons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1014\n",
       "1.0    1378\n",
       "0.0     790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of labels\n",
    "pd.value_counts(Y.values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove labels from feature set\n",
    "X.drop(['GTcons'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X4 = X.reindex_axis(sorted(X.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Machine Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine_learning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Random Forest Classifier **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi_run'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine Number of trees: Out of Bag Error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# Train on 70% of the data and test on 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(oob_score=True) \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OOB prediction of accuracy is: 97.03637180062866%\n"
     ]
    }
   ],
   "source": [
    "print('The OOB prediction of accuracy is: {oob}%'.format(oob=model.oob_score_ * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 150\n",
    "trees = []\n",
    "oob = []\n",
    "for i in range(1, n_estimators):\n",
    "    model.set_params(n_estimators=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    trees += [i]\n",
    "    oob += [model.oob_score_] \n",
    "    \n",
    "    \n",
    "df_oob = pd.DataFrame()\n",
    "df_oob['trees'] = trees\n",
    "df_oob['oob'] = oob\n",
    "\n",
    "\n",
    "plt.plot(trees, oob)\n",
    "\n",
    "plt.xlabel(\"Number of Trees [n_estimators]\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.savefig('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/ins_alldata_6000_trees_oob.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Model Using Optimal Tuning Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=4,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, random_state=4, class_weight=\"balanced\") \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "feature_importances.sort()\n",
    "feature_importances.plot(kind=\"barh\", figsize=(8,30))\n",
    "plt.savefig('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/ins_alldata_6000_featImp.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/ins_alldata_6000_featImp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = X4[['Ill300x.ref_reason_alignmentScore','Ill300x.alt_insertSize_std','Ill300x.alt_count','Ill250.ref_count','IllMP.alt_reason_alignmentScore','Ill250.ref_reason_alignmentScore','Ill250.alt_alnScore_std','Ill300x.ref_count','Ill300x.alt_reason_alignmentScore','Ill250.alt_insertSize_std','TenX.HP2_alt_reason_alignmentScore','Ill250.alt_reason_alignmentScore','Ill250.ref_alnScore_std','Ill250.ref_insertSize_std','Ill250.ref_insertSize_mean','IllMP.alt_insertSize_std','Ill300x.alt_alnScore_std','IllMP.ref_reason_alignmentScore','IllMP.alt_alnScore_mean','Ill250.alt_count','Ill250.ref_alnScore_mean','TenX.HP2_alt_count','pacbio.ref_reason_alignmentScore','IllMP.ref_alnScore_std','IllMP.ref_insertSize_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(X_.corr(), annot=True, fmt=\".2f\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.yticks(rotation='horizontal')\n",
    "plt.savefig('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/ins_alldata_6000_heatmap.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9c2ec6d3713b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision score of the training subset: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy score of the training subset: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "print('Precision score of the training subset: {:.3f}'.format(precision_score(y_test, pred, average='micro'))) \n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score of the training subset: {:.3f}'.format(accuracy_score(y_test, pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add original labels and predicted labels back to the original dataframe\n",
    "df_Xtest = pd.DataFrame(X_test)\n",
    "labels = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['predicted_label'] = pred\n",
    "df_Xtest['GTcons'] = df_train['GTcons']\n",
    "df_Xtest['chrom'] = df_train['chrom']\n",
    "df_Xtest['start'] = df_train['start']\n",
    "df_Xtest['end'] = df_train['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['GTcons'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['GTcons'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['GTcons'].replace(2.0, 'Homozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df_Xtest['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df_Xtest['predicted_label'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ytest = df_Xtest['GTcons']\n",
    "predict = df_Xtest['predicted_label']\n",
    "print(confusion_matrix(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Predict\n",
    "\n",
    "Predict labels for test set\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.drop(['GTcons'],axis=1, inplace=True)\n",
    "X2 = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_header = list(df_test.columns.values)\n",
    "X2.columns = df_test_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)\n",
    "pred_prob = model.predict_proba(X5)\n",
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_test_2['chrom']\n",
    "X5['GTcons'] = df_test_2['GTcons']\n",
    "X5['start'] = df_test_2['start']\n",
    "X5['end'] = df_test_2['end']\n",
    "X5['Size'] = df_test_2['Size']\n",
    "X5['GTsupp'] = df_test_2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])\n",
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])\n",
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_df1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_df2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6['GTcons'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NaN Labels\n",
    "X6 = X6[np.isfinite(X6['GTcons'])]\n",
    "X6 = X6[np.isfinite(X6['predicted_GTcons_label'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat = pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "conf_mat.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/6000_confMatrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Labels with Pred_Prob >=0.9 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "conf_mat = pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "conf_mat.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/6000_confMatrix_hi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Predict\n",
    "\n",
    "Predict labels for minus 1 (unknown label) set\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_min1.drop(['GTcons'],axis=1, inplace=True)\n",
    "X2 = df_min1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/2049 with 0 missing, elapsed time: 3.593\n",
      "Imputing row 101/2049 with 0 missing, elapsed time: 3.596\n",
      "Imputing row 201/2049 with 0 missing, elapsed time: 3.608\n",
      "Imputing row 301/2049 with 0 missing, elapsed time: 3.611\n",
      "Imputing row 401/2049 with 4 missing, elapsed time: 3.657\n",
      "Imputing row 501/2049 with 4 missing, elapsed time: 3.682\n",
      "Imputing row 601/2049 with 4 missing, elapsed time: 3.702\n",
      "Imputing row 701/2049 with 4 missing, elapsed time: 3.719\n",
      "Imputing row 801/2049 with 6 missing, elapsed time: 3.770\n",
      "Imputing row 901/2049 with 6 missing, elapsed time: 3.795\n",
      "Imputing row 1001/2049 with 6 missing, elapsed time: 3.820\n",
      "Imputing row 1101/2049 with 1 missing, elapsed time: 3.871\n",
      "Imputing row 1201/2049 with 1 missing, elapsed time: 3.889\n",
      "Imputing row 1301/2049 with 1 missing, elapsed time: 3.901\n",
      "Imputing row 1401/2049 with 60 missing, elapsed time: 3.930\n",
      "Imputing row 1501/2049 with 1 missing, elapsed time: 3.958\n",
      "Imputing row 1601/2049 with 1 missing, elapsed time: 3.979\n",
      "Imputing row 1701/2049 with 1 missing, elapsed time: 3.990\n",
      "Imputing row 1801/2049 with 2 missing, elapsed time: 4.032\n",
      "Imputing row 1901/2049 with 2 missing, elapsed time: 4.056\n",
      "Imputing row 2001/2049 with 2 missing, elapsed time: 4.071\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>Ill250.amb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>876.727273</td>\n",
       "      <td>32.283097</td>\n",
       "      <td>11.0</td>\n",
       "      <td>465.909091</td>\n",
       "      <td>74.904126</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>823.752174</td>\n",
       "      <td>145.390881</td>\n",
       "      <td>230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>813.630873</td>\n",
       "      <td>161.779880</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1219549.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>913.571429</td>\n",
       "      <td>24.818525</td>\n",
       "      <td>7.0</td>\n",
       "      <td>410.285714</td>\n",
       "      <td>52.562111</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>845.492823</td>\n",
       "      <td>158.682558</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6802561.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                876.727273                32.283097              11.0   \n",
       "1                  0.000000                 0.000000               0.0   \n",
       "2                913.571429                24.818525               7.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  465.909091                  74.904126   \n",
       "1                    0.000000                   0.000000   \n",
       "2                  410.285714                  52.562111   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              11.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               7.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std  Ill250.amb_count  \\\n",
       "0                823.752174               145.390881             230.0   \n",
       "1                813.630873               161.779880             149.0   \n",
       "2                845.492823               158.682558             209.0   \n",
       "\n",
       "       ...        pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0      ...                               0.0                        0.0   \n",
       "1      ...                               0.0                        0.0   \n",
       "2      ...                           10175.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0       0.0       0.0         0.0   \n",
       "1                               0.0       0.0       0.0         0.0   \n",
       "2                               1.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct      start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  1004213.0            1.0            1.0  \n",
       "1         0.0  1219549.0            1.0            1.0  \n",
       "2         0.0  6802561.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 175 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min1_header = list(df_min1.columns.values)\n",
    "X2.columns = df_min1_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>Ill250.amb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>876.727273</td>\n",
       "      <td>32.283097</td>\n",
       "      <td>11.0</td>\n",
       "      <td>465.909091</td>\n",
       "      <td>74.904126</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>823.752174</td>\n",
       "      <td>145.390881</td>\n",
       "      <td>230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>813.630873</td>\n",
       "      <td>161.779880</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1219549.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>913.571429</td>\n",
       "      <td>24.818525</td>\n",
       "      <td>7.0</td>\n",
       "      <td>410.285714</td>\n",
       "      <td>52.562111</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>845.492823</td>\n",
       "      <td>158.682558</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6802561.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                876.727273                32.283097              11.0   \n",
       "1                  0.000000                 0.000000               0.0   \n",
       "2                913.571429                24.818525               7.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  465.909091                  74.904126   \n",
       "1                    0.000000                   0.000000   \n",
       "2                  410.285714                  52.562111   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              11.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               7.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std  Ill250.amb_count  \\\n",
       "0                823.752174               145.390881             230.0   \n",
       "1                813.630873               161.779880             149.0   \n",
       "2                845.492823               158.682558             209.0   \n",
       "\n",
       "       ...        pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0      ...                               0.0                        0.0   \n",
       "1      ...                               0.0                        0.0   \n",
       "2      ...                           10175.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0       0.0       0.0         0.0   \n",
       "1                               0.0       0.0       0.0         0.0   \n",
       "2                               1.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct      start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  1004213.0            1.0            1.0  \n",
       "1         0.0  1219549.0            1.0            1.0  \n",
       "2         0.0  6802561.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 175 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)\n",
    "pred_prob = model.predict_proba(X5)\n",
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_min1_2['chrom']\n",
    "X5['GTcons'] = df_min1_2['GTcons']\n",
    "X5['start'] = df_min1_2['start']\n",
    "X5['end'] = df_min1_2['end']\n",
    "X5['Size'] = df_min1_2['Size']\n",
    "X5['GTsupp'] = df_min1_2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])\n",
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])\n",
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_min1_df1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_min1_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_min1_df2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
