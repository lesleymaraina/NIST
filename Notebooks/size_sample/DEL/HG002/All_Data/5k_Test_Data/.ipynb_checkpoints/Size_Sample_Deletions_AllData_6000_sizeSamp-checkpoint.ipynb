{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data: Consensus Genotype\n",
    "Size_Sample_Insertions_AllData_6000\n",
    "\n",
    "* Size Ranges\n",
    "* Training Dataset size : 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import io\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import plotly.plotly as py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "from bokeh.charts import TimeSeries\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.charts import Scatter, Histogram, output_file, show\n",
    "from bokeh.plotting import figure, show, output_file, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "import bokeh.palettes as palettes\n",
    "from bokeh.models import HoverTool, BoxSelectTool, Legend\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Training Set\n",
    "\n",
    "Count : 6000\n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3182, 188)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Training Data\n",
    "df_train = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/train/6k.INS.test.csv')\n",
    "df_train_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/train/6k.INS.test.csv')\n",
    "df_train.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame()\n",
    "train_set = df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "train_set['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "train_set['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Count of Labels in Training Set **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heterozygous_Variant    1378\n",
       "Homozygous_Variant      1014\n",
       "Homozygous_Reference     790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_set['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_train.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_train.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_train.drop(['sample'], axis=1, inplace = True)\n",
    "df_train.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_train.drop(['type'], axis=1, inplace = True)\n",
    "df_train.drop(['id'], axis=1, inplace = True)\n",
    "df_train.drop(['New_ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['chrom'].replace('X', 23, inplace=True)\n",
    "df_train['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Test Set\n",
    "\n",
    "Size separated\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hom_ref'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1039, 188)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Test Data\n",
    "# SVanalyzer generated training data\n",
    "df_test_size = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/new_sizeSample_testSet/INS/All_size_sample_TestSet.csv')\n",
    "df_test_size_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/new_sizeSample_testSet/INS/All_size_sample_TestSet.csv')\n",
    "df_test_size.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_test_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_test_size.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_test_size.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_test_size.drop(['sample'], axis=1, inplace = True)\n",
    "df_test_size.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_test_size.drop(['type'], axis=1, inplace = True)\n",
    "df_test_size.drop(['id'], axis=1, inplace = True)\n",
    "df_test_size.drop(['New_ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>977.521739</td>\n",
       "      <td>7.329924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>417.173913</td>\n",
       "      <td>82.969168</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.705882</td>\n",
       "      <td>166.36645</td>\n",
       "      <td>...</td>\n",
       "      <td>11649.10345</td>\n",
       "      <td>4516.179216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986553</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       1                977.521739                 7.329924   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              23.0                  417.173913                  82.969168   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              23.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                888.705882                166.36645      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                 11649.10345                4516.179216   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              29.0         0         0           0   \n",
       "\n",
       "   segdup_pct    start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  2986553              0            0.0  \n",
       "\n",
       "[1 rows x 176 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_size.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_size['chrom'].replace('X', 23, inplace=True)\n",
    "df_test_size['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Impute missing values using KNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>962.019608</td>\n",
       "      <td>14.772112</td>\n",
       "      <td>51.0</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>81.200068</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.634831</td>\n",
       "      <td>146.493457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>920006</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       2                958.307692                17.827742   \n",
       "1       2                958.307692                17.827742   \n",
       "2       2                962.019608                14.772112   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "1              52.0                  403.673077                  79.999452   \n",
       "2              51.0                  415.000000                  81.200068   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "1                              52.0                            0.0   \n",
       "2                              51.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "1                867.666667               144.039804      ...         \n",
       "2                866.634831               146.493457      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0         0         0           0   \n",
       "1                               0.0         0         0           0   \n",
       "2                               0.0         0         0           0   \n",
       "\n",
       "   segdup_pct   start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991              1            1.0  \n",
       "1         0.0  919991              1            1.0  \n",
       "2         0.0  920006              1            1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training data in a new variable which will be converted to a matrix\n",
    "X = df_train\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/3182 with 0 missing, elapsed time: 9.156\n",
      "Imputing row 101/3182 with 0 missing, elapsed time: 9.157\n",
      "Imputing row 201/3182 with 0 missing, elapsed time: 9.168\n",
      "Imputing row 301/3182 with 0 missing, elapsed time: 9.173\n",
      "Imputing row 401/3182 with 0 missing, elapsed time: 9.181\n",
      "Imputing row 501/3182 with 0 missing, elapsed time: 9.185\n",
      "Imputing row 601/3182 with 0 missing, elapsed time: 9.186\n",
      "Imputing row 701/3182 with 4 missing, elapsed time: 9.231\n",
      "Imputing row 801/3182 with 4 missing, elapsed time: 9.249\n",
      "Imputing row 901/3182 with 4 missing, elapsed time: 9.275\n",
      "Imputing row 1001/3182 with 4 missing, elapsed time: 9.296\n",
      "Imputing row 1101/3182 with 4 missing, elapsed time: 9.313\n",
      "Imputing row 1201/3182 with 59 missing, elapsed time: 9.348\n",
      "Imputing row 1301/3182 with 6 missing, elapsed time: 9.391\n",
      "Imputing row 1401/3182 with 6 missing, elapsed time: 9.425\n",
      "Imputing row 1501/3182 with 6 missing, elapsed time: 9.451\n",
      "Imputing row 1601/3182 with 6 missing, elapsed time: 9.477\n",
      "Imputing row 1701/3182 with 6 missing, elapsed time: 9.502\n",
      "Imputing row 1801/3182 with 60 missing, elapsed time: 9.532\n",
      "Imputing row 1901/3182 with 1 missing, elapsed time: 9.581\n",
      "Imputing row 2001/3182 with 1 missing, elapsed time: 9.591\n",
      "Imputing row 2101/3182 with 1 missing, elapsed time: 9.603\n",
      "Imputing row 2201/3182 with 1 missing, elapsed time: 9.608\n",
      "Imputing row 2301/3182 with 1 missing, elapsed time: 9.620\n",
      "Imputing row 2401/3182 with 1 missing, elapsed time: 9.630\n",
      "Imputing row 2501/3182 with 1 missing, elapsed time: 9.638\n",
      "Imputing row 2601/3182 with 2 missing, elapsed time: 9.692\n",
      "Imputing row 2701/3182 with 2 missing, elapsed time: 9.705\n",
      "Imputing row 2801/3182 with 2 missing, elapsed time: 9.715\n",
      "Imputing row 2901/3182 with 2 missing, elapsed time: 9.726\n",
      "Imputing row 3001/3182 with 2 missing, elapsed time: 9.737\n",
      "Imputing row 3101/3182 with 2 missing, elapsed time: 9.750\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "X=X.as_matrix()\n",
    "\n",
    "#Imput missing values from three closest observations\n",
    "X_imputed=KNN(k=3).complete(X)\n",
    "X=pd.DataFrame(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>962.019608</td>\n",
       "      <td>14.772112</td>\n",
       "      <td>51.0</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>81.200068</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.634831</td>\n",
       "      <td>146.493457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>920006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0     2.0                958.307692                17.827742   \n",
       "1     2.0                958.307692                17.827742   \n",
       "2     2.0                962.019608                14.772112   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "1              52.0                  403.673077                  79.999452   \n",
       "2              51.0                  415.000000                  81.200068   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "1                              52.0                            0.0   \n",
       "2                              51.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "1                867.666667               144.039804      ...         \n",
       "2                866.634831               146.493457      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0       0.0       0.0         0.0   \n",
       "1                               0.0       0.0       0.0         0.0   \n",
       "2                               0.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct     start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991.0            1.0            1.0  \n",
       "1         0.0  919991.0            1.0            1.0  \n",
       "2         0.0  920006.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header values in a list, will be used later to re-label the matrix post KNN imputation\n",
    "dftrain_header = list(df_train.columns.values)\n",
    "X.columns = dftrain_header\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Labels in a new 'Y' DataFrame\n",
    "Y = pd.DataFrame()\n",
    "Y = X['GTcons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1014\n",
       "1.0    1378\n",
       "0.0     790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of labels\n",
    "pd.value_counts(Y.values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove labels from feature set\n",
    "X.drop(['GTcons'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X4 = X.reindex_axis(sorted(X.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Machine Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine_learning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Random Forest Classifier **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi_run'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine Number of trees: Out of Bag Error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# Train on 70% of the data and test on 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(oob_score=True) \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The OOB prediction of accuracy is: {oob}%'.format(oob=model.oob_score_ * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 150\n",
    "trees = []\n",
    "oob = []\n",
    "for i in range(1, n_estimators):\n",
    "    model.set_params(n_estimators=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    trees += [i]\n",
    "    oob += [model.oob_score_] \n",
    "    \n",
    "    \n",
    "df_oob = pd.DataFrame()\n",
    "df_oob['trees'] = trees\n",
    "df_oob['oob'] = oob\n",
    "\n",
    "\n",
    "plt.plot(trees, oob)\n",
    "\n",
    "plt.xlabel(\"Number of Trees [n_estimators]\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.savefig('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/ins_alldata_6000_trees_oob.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Model Using Optimal Tuning Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=4,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, random_state=4, class_weight=\"balanced\") \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the training subset: 0.994\n",
      "Accuracy score of the training subset: 0.994\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the training subset: {:.3f}'.format(precision_score(y_test, pred, average='micro'))) \n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score of the training subset: {:.3f}'.format(accuracy_score(y_test, pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add original labels and predicted labels back to the original dataframe\n",
    "df_Xtest = pd.DataFrame(X_test)\n",
    "labels = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['predicted_label'] = pred\n",
    "df_Xtest['GTcons'] = df_train['GTcons']\n",
    "df_Xtest['chrom'] = df_train['chrom']\n",
    "df_Xtest['start'] = df_train['start']\n",
    "df_Xtest['end'] = df_train['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['GTcons'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['GTcons'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['GTcons'].replace(2.0, 'Homozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homozygous_Reference    224\n",
       "Heterozygous_Variant    444\n",
       "Homozygous_Variant      287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_Xtest['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homozygous_Reference    222\n",
       "Heterozygous_Variant    450\n",
       "Homozygous_Variant      283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_Xtest['predicted_label'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[444   0   0]\n",
      " [  2 222   0]\n",
      " [  4   0 283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ytest = df_Xtest['GTcons']\n",
    "predict = df_Xtest['predicted_label']\n",
    "print(confusion_matrix(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>450</td>\n",
       "      <td>222</td>\n",
       "      <td>283</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   444                     0   \n",
       "Homozygous_Reference                     2                   222   \n",
       "Homozygous_Variant                       4                     0   \n",
       "All                                    450                   222   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  444  \n",
       "Homozygous_Reference                   0  224  \n",
       "Homozygous_Variant                   283  287  \n",
       "All                                  283  955  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       0.99      1.00      0.99       444\n",
      "Homozygous_Reference       1.00      0.99      1.00       224\n",
      "  Homozygous_Variant       1.00      0.99      0.99       287\n",
      "\n",
      "         avg / total       0.99      0.99      0.99       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Predict\n",
    "\n",
    "Predict labels for test set\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_size.drop(['GTcons'],axis=1, inplace=True)\n",
    "X2 = df_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1039 with 2 missing, elapsed time: 0.874\n",
      "Imputing row 101/1039 with 3 missing, elapsed time: 0.887\n",
      "Imputing row 201/1039 with 1 missing, elapsed time: 0.901\n",
      "Imputing row 301/1039 with 3 missing, elapsed time: 0.913\n",
      "Imputing row 401/1039 with 3 missing, elapsed time: 0.927\n",
      "Imputing row 501/1039 with 2 missing, elapsed time: 0.938\n",
      "Imputing row 601/1039 with 1 missing, elapsed time: 0.956\n",
      "Imputing row 701/1039 with 3 missing, elapsed time: 0.968\n",
      "Imputing row 801/1039 with 2 missing, elapsed time: 0.977\n",
      "Imputing row 901/1039 with 2 missing, elapsed time: 0.989\n",
      "Imputing row 1001/1039 with 2 missing, elapsed time: 1.005\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>Ill250.amb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>977.521739</td>\n",
       "      <td>7.329924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>417.173913</td>\n",
       "      <td>82.969168</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.705882</td>\n",
       "      <td>166.366450</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11649.10345</td>\n",
       "      <td>4516.179216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>873.616352</td>\n",
       "      <td>161.479434</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10858.17647</td>\n",
       "      <td>4360.693980</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33972943.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.656051</td>\n",
       "      <td>164.646068</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10686.04651</td>\n",
       "      <td>4080.610431</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55880548.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                977.521739                 7.329924              23.0   \n",
       "1                  0.000000                 0.000000               0.0   \n",
       "2                  0.000000                 0.000000               0.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  417.173913                  82.969168   \n",
       "1                    0.000000                   0.000000   \n",
       "2                    0.000000                   0.000000   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              23.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std  Ill250.amb_count  \\\n",
       "0                888.705882               166.366450             170.0   \n",
       "1                873.616352               161.479434             159.0   \n",
       "2                879.656051               164.646068             157.0   \n",
       "\n",
       "       ...        pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0      ...                       11649.10345                4516.179216   \n",
       "1      ...                       10858.17647                4360.693980   \n",
       "2      ...                       10686.04651                4080.610431   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              29.0       0.0       0.0         0.0   \n",
       "1                              51.0       0.0       0.0         0.0   \n",
       "2                              43.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0   2986553.0            0.0            0.0  \n",
       "1         0.0  33972943.0            1.0            1.0  \n",
       "2         0.0  55880548.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 175 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_header = list(df_test_size.columns.values)\n",
    "X2.columns = df_test_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>Ill250.amb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>977.521739</td>\n",
       "      <td>7.329924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>417.173913</td>\n",
       "      <td>82.969168</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.705882</td>\n",
       "      <td>166.366450</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11649.10345</td>\n",
       "      <td>4516.179216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>873.616352</td>\n",
       "      <td>161.479434</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10858.17647</td>\n",
       "      <td>4360.693980</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33972943.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.656051</td>\n",
       "      <td>164.646068</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10686.04651</td>\n",
       "      <td>4080.610431</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55880548.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                977.521739                 7.329924              23.0   \n",
       "1                  0.000000                 0.000000               0.0   \n",
       "2                  0.000000                 0.000000               0.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  417.173913                  82.969168   \n",
       "1                    0.000000                   0.000000   \n",
       "2                    0.000000                   0.000000   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              23.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std  Ill250.amb_count  \\\n",
       "0                888.705882               166.366450             170.0   \n",
       "1                873.616352               161.479434             159.0   \n",
       "2                879.656051               164.646068             157.0   \n",
       "\n",
       "       ...        pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0      ...                       11649.10345                4516.179216   \n",
       "1      ...                       10858.17647                4360.693980   \n",
       "2      ...                       10686.04651                4080.610431   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              29.0       0.0       0.0         0.0   \n",
       "1                              51.0       0.0       0.0         0.0   \n",
       "2                              43.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0   2986553.0            0.0            0.0  \n",
       "1         0.0  33972943.0            1.0            1.0  \n",
       "2         0.0  55880548.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 175 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)\n",
    "pred_prob = model.predict_proba(X5)\n",
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_test_size_2['chrom']\n",
    "X5['GTcons'] = df_test_size_2['GTcons']\n",
    "X5['start'] = df_test_size_2['start']\n",
    "X5['end'] = df_test_size_2['end']\n",
    "X5['Size'] = df_test_size_2['Size']\n",
    "X5['GTsupp'] = df_test_size_2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])\n",
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])\n",
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/df_size_sampTest_df1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/df_size_sampTest_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/df_size_sampTest_df2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6['GTcons'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NaN Labels\n",
    "X6 = X6[np.isfinite(X6['GTcons'])]\n",
    "X6 = X6[np.isfinite(X6['predicted_GTcons_label'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[292   1   0]\n",
      " [  2 456   1]\n",
      " [  2   1 284]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.993\n",
      "Accuracy score of the prediction subset: 0.993\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>284</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>458</td>\n",
       "      <td>296</td>\n",
       "      <td>285</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   456                     2   \n",
       "Homozygous_Reference                     1                   292   \n",
       "Homozygous_Variant                       1                     2   \n",
       "All                                    458                   296   \n",
       "\n",
       "Predicted             Homozygous_Variant   All  \n",
       "True                                            \n",
       "Heterozygous_Variant                   1   459  \n",
       "Homozygous_Reference                   0   293  \n",
       "Homozygous_Variant                   284   287  \n",
       "All                                  285  1039  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat = pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "conf_mat.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/Test_SizeSamp_All_confMatrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Labels with Pred_Prob >=0.9 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>418</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   418                     0   \n",
       "Homozygous_Reference                     0                   254   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                    418                   254   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  418  \n",
       "Homozygous_Reference                   0  254  \n",
       "Homozygous_Variant                   253  253  \n",
       "All                                  253  925  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "conf_mat = pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "conf_mat.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/Test_SizeSamp_All_confMatrix_hi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       1.00      1.00      1.00       418\n",
      "Homozygous_Reference       1.00      1.00      1.00       254\n",
      "  Homozygous_Variant       1.00      1.00      1.00       253\n",
      "\n",
      "         avg / total       1.00      1.00      1.00       925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Size Separate Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size Bins\n",
    "bins = [0, 50, 100,300,400,1000,5999,45516]\n",
    "X6['Size'] = X6['Size'].abs()\n",
    "group_names_size = ['0-50', '50-100', '100-300', '300-400', '400-1000', '1000-5999', '6000+']\n",
    "X6['size_bin'] = pd.cut(X6['Size'], bins, labels=group_names_size)\n",
    "\n",
    "#Separate dataframes based on size_bin\n",
    "df_20to50 = X6[X6['size_bin'].str.contains('0-50')]\n",
    "df_50to100 = X6[X6['size_bin'].str.contains('50-100')]\n",
    "df_100to300 = X6[X6['size_bin'].str.contains('100-300')]\n",
    "df_300to400 = X6[X6['size_bin'].str.contains('300-400')]\n",
    "df_400to1000 = X6[X6['size_bin'].str.contains('400-1000')]\n",
    "df_1000to6000 = X6[X6['size_bin'].str.contains('1000-5999')]\n",
    "df_6000 = X6[X6['size_bin'].str.contains('6000+')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>93</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    93                     0   \n",
       "Homozygous_Reference                     0                    61   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                     93                    61   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   93  \n",
       "Homozygous_Reference                   0   61  \n",
       "Homozygous_Variant                    46   46  \n",
       "All                                   46  200  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrices\n",
    "consensus_GT = df_20to50['GTcons']\n",
    "predict = df_20to50['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_50to100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>96</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    96                     0   \n",
       "Homozygous_Reference                     0                    47   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                     96                    47   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   96  \n",
       "Homozygous_Reference                   0   47  \n",
       "Homozygous_Variant                    57   57  \n",
       "All                                   57  200  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_50to100['GTcons']\n",
    "predict = df_50to100['predicted_GTcons_label']\n",
    "print('df_50to100')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_100to300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    85                     0   \n",
       "Homozygous_Reference                     0                    63   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                     85                    63   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   85  \n",
       "Homozygous_Reference                   0   63  \n",
       "Homozygous_Variant                    52   52  \n",
       "All                                   52  200  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_100to300['GTcons']\n",
    "predict = df_100to300['predicted_GTcons_label']\n",
    "print('df_100to300')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_300to400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>104</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   104                     1   \n",
       "Homozygous_Reference                     0                    55   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                    104                    56   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  105  \n",
       "Homozygous_Reference                   0   55  \n",
       "Homozygous_Variant                    38   38  \n",
       "All                                   38  198  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_300to400['GTcons']\n",
    "predict = df_300to400['predicted_GTcons_label']\n",
    "print('df_300to400')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_400to1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>58</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    42                     1   \n",
       "Homozygous_Reference                     0                    41   \n",
       "Homozygous_Variant                       0                     1   \n",
       "All                                     42                    43   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   43  \n",
       "Homozygous_Reference                   0   41  \n",
       "Homozygous_Variant                    58   59  \n",
       "All                                   58  143  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_400to1000['GTcons']\n",
    "predict = df_400to1000['predicted_GTcons_label']\n",
    "print('df_400to1000')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1000to6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    35                     0   \n",
       "Homozygous_Reference                     1                    25   \n",
       "Homozygous_Variant                       1                     1   \n",
       "All                                     37                    26   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   35  \n",
       "Homozygous_Reference                   0   26  \n",
       "Homozygous_Variant                    30   32  \n",
       "All                                   30   93  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_1000to6000['GTcons']\n",
    "predict = df_1000to6000['predicted_GTcons_label']\n",
    "print('df_1000to6000')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Variant  All\n",
       "True                                                               \n",
       "Heterozygous_Variant                     1                   1    2\n",
       "Homozygous_Variant                       0                   3    3\n",
       "All                                      1                   4    5"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_6000['GTcons']\n",
    "predict = df_6000['predicted_GTcons_label']\n",
    "print('df_6000')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 to 50 bp Hom Var 0.9565217391304348\n",
      "20 to 50 bp Het Var 0.9720430107526884\n",
      "20 to 50 bp Hom Ref 0.9745901639344263\n",
      "50to100 bp Hom Var 0.9728070175438598\n",
      "50to100 bp Het Var 0.9713541666666671\n",
      "50to100 bp Hom Ref 0.973404255319149\n",
      "100to300 bp Hom Var 0.9711538461538463\n",
      "100to300 bp Het Var 0.9664705882352943\n",
      "100to300 bp Hom Ref 0.9452380952380953\n",
      "300to400 bp Hom Var 0.9486842105263159\n",
      "300to400 bp Het Var 0.9652380952380956\n",
      "300to400 bp Hom Ref 0.9790909090909092\n",
      "400to1000 bp Hom Var 0.9305084745762714\n",
      "400to1000 bp Het Var 0.9337209302325581\n",
      "400to1000 bp Hom Ref 0.9475609756097563\n",
      "1000to6000 bp Hom Var 0.8671874999999998\n",
      "1000to6000 bp Het Var 0.9514285714285714\n",
      "1000to6000 bp Hom Ref 0.8365384615384616\n",
      "6000 bp Hom Var 0.9166666666666666\n",
      "6000 bp Het Var 0.6499999999999999\n",
      "6000 bp Hom Ref nan\n"
     ]
    }
   ],
   "source": [
    "#Calculate average pred prob for each group\n",
    "df_20to50_homVar = df_20to50[df_20to50['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_20to50_hetVar = df_20to50[df_20to50['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_20to50_homRef = df_20to50[df_20to50['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_20to50_homVar.mean()\n",
    "df_20to50_hetVar.mean()\n",
    "df_20to50_homRef.mean()\n",
    "print('20 to 50 bp Hom Var {}'.format(df_20to50_homVar.mean())) \n",
    "print('20 to 50 bp Het Var {}'.format(df_20to50_hetVar.mean())) \n",
    "print('20 to 50 bp Hom Ref {}'.format(df_20to50_homRef.mean())) \n",
    "\n",
    "df_50to100_homVar = df_50to100[df_50to100['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_50to100_hetVar = df_50to100[df_50to100['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_50to100_homRef = df_50to100[df_50to100['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_50to100_homVar.mean()\n",
    "df_50to100_hetVar.mean()\n",
    "df_50to100_homRef.mean()\n",
    "print('50to100 bp Hom Var {}'.format(df_50to100_homVar.mean())) \n",
    "print('50to100 bp Het Var {}'.format(df_50to100_hetVar.mean())) \n",
    "print('50to100 bp Hom Ref {}'.format(df_50to100_homRef.mean())) \n",
    "\n",
    "df_100to300_homVar = df_100to300[df_100to300['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_100to300_hetVar = df_100to300[df_100to300['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_100to300_homRef = df_100to300[df_100to300['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_100to300_homVar.mean()\n",
    "df_100to300_hetVar.mean()\n",
    "df_100to300_homRef.mean()\n",
    "print('100to300 bp Hom Var {}'.format(df_100to300_homVar.mean())) \n",
    "print('100to300 bp Het Var {}'.format(df_100to300_hetVar.mean())) \n",
    "print('100to300 bp Hom Ref {}'.format(df_100to300_homRef.mean())) \n",
    "\n",
    "df_300to400_homVar = df_300to400[df_300to400['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_300to400_hetVar = df_300to400[df_300to400['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_300to400_homRef = df_300to400[df_300to400['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_300to400_homVar.mean()\n",
    "df_300to400_hetVar.mean()\n",
    "df_300to400_homRef.mean()\n",
    "print('300to400 bp Hom Var {}'.format(df_300to400_homVar.mean())) \n",
    "print('300to400 bp Het Var {}'.format(df_300to400_hetVar.mean())) \n",
    "print('300to400 bp Hom Ref {}'.format(df_300to400_homRef.mean())) \n",
    "\n",
    "df_400to1000_homVar = df_400to1000[df_400to1000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_400to1000_hetVar = df_400to1000[df_400to1000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_400to1000_homRef = df_400to1000[df_400to1000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_400to1000_homVar.mean()\n",
    "df_400to1000_hetVar.mean()\n",
    "df_400to1000_homRef.mean()\n",
    "print('400to1000 bp Hom Var {}'.format(df_400to1000_homVar.mean())) \n",
    "print('400to1000 bp Het Var {}'.format(df_400to1000_hetVar.mean())) \n",
    "print('400to1000 bp Hom Ref {}'.format(df_400to1000_homRef.mean())) \n",
    "\n",
    "df_1000to6000_homVar = df_1000to6000[df_1000to6000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_1000to6000_hetVar = df_1000to6000[df_1000to6000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_1000to6000_homRef = df_1000to6000[df_1000to6000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_1000to6000_homVar.mean()\n",
    "df_1000to6000_hetVar.mean()\n",
    "df_1000to6000_homRef.mean()\n",
    "print('1000to6000 bp Hom Var {}'.format(df_1000to6000_homVar.mean())) \n",
    "print('1000to6000 bp Het Var {}'.format(df_1000to6000_hetVar.mean())) \n",
    "print('1000to6000 bp Hom Ref {}'.format(df_1000to6000_homRef.mean())) \n",
    "\n",
    "df_6000_homVar = df_6000[df_6000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_6000_hetVar = df_6000[df_6000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_6000_homRef = df_6000[df_6000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_6000_homVar.mean()\n",
    "df_6000_hetVar.mean()\n",
    "df_6000_homRef.mean()\n",
    "print('6000 bp Hom Var {}'.format(df_6000_homVar.mean())) \n",
    "print('6000 bp Het Var {}'.format(df_6000_hetVar.mean())) \n",
    "print('6000 bp Hom Ref {}'.format(df_6000_homRef.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20to50_homVar.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
