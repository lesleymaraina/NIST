{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data: Consensus Genotype\n",
    "Size_Sample_Insertions_AllData_6000\n",
    "\n",
    "* Size Ranges\n",
    "* Training Dataset size : 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import io\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import plotly.plotly as py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "from bokeh.charts import TimeSeries\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.charts import Scatter, Histogram, output_file, show\n",
    "from bokeh.plotting import figure, show, output_file, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "import bokeh.palettes as palettes\n",
    "from bokeh.models import HoverTool, BoxSelectTool, Legend\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Training Set\n",
    "\n",
    "Count : 6000\n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3182, 188)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Training Data\n",
    "df_train = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/train/6k.INS.test.csv')\n",
    "df_train_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/5k_testSet/train/6k.INS.test.csv')\n",
    "df_train.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame()\n",
    "train_set = df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "train_set['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "train_set['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Count of Labels in Training Set **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homozygous_Variant      1014\n",
       "Heterozygous_Variant    1378\n",
       "Homozygous_Reference     790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_set['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_train.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_train.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_train.drop(['sample'], axis=1, inplace = True)\n",
    "df_train.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_train.drop(['type'], axis=1, inplace = True)\n",
    "df_train.drop(['id'], axis=1, inplace = True)\n",
    "df_train.drop(['New_ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['chrom'].replace('X', 23, inplace=True)\n",
    "df_train['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Test Set\n",
    "\n",
    "Size separated\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hom_ref'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1039, 188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Test Data\n",
    "# SVanalyzer generated training data\n",
    "df_test_size = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/new_sizeSample_testSet/INS/All_size_sample_TestSet.csv')\n",
    "df_test_size_2 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/dataframes/Step1_CombinedDFs/new_sizeSample_testSet/INS/All_size_sample_TestSet.csv')\n",
    "df_test_size.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_test_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_test_size.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_test_size.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_test_size.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_test_size.drop(['sample'], axis=1, inplace = True)\n",
    "df_test_size.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_test_size.drop(['type'], axis=1, inplace = True)\n",
    "df_test_size.drop(['id'], axis=1, inplace = True)\n",
    "df_test_size.drop(['New_ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>977.521739</td>\n",
       "      <td>7.329924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>417.173913</td>\n",
       "      <td>82.969168</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.705882</td>\n",
       "      <td>166.36645</td>\n",
       "      <td>...</td>\n",
       "      <td>11649.10345</td>\n",
       "      <td>4516.179216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986553</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       1                977.521739                 7.329924   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              23.0                  417.173913                  82.969168   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              23.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                888.705882                166.36645      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                 11649.10345                4516.179216   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              29.0         0         0           0   \n",
       "\n",
       "   segdup_pct    start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  2986553              0            0.0  \n",
       "\n",
       "[1 rows x 176 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_size.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_size['chrom'].replace('X', 23, inplace=True)\n",
    "df_test_size['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Impute missing values using KNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>962.019608</td>\n",
       "      <td>14.772112</td>\n",
       "      <td>51.0</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>81.200068</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.634831</td>\n",
       "      <td>146.493457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>920006</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       2                958.307692                17.827742   \n",
       "1       2                958.307692                17.827742   \n",
       "2       2                962.019608                14.772112   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "1              52.0                  403.673077                  79.999452   \n",
       "2              51.0                  415.000000                  81.200068   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "1                              52.0                            0.0   \n",
       "2                              51.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "1                867.666667               144.039804      ...         \n",
       "2                866.634831               146.493457      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0         0         0           0   \n",
       "1                               0.0         0         0           0   \n",
       "2                               0.0         0         0           0   \n",
       "\n",
       "   segdup_pct   start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991              1            1.0  \n",
       "1         0.0  919991              1            1.0  \n",
       "2         0.0  920006              1            1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training data in a new variable which will be converted to a matrix\n",
    "X = df_train\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/3182 with 0 missing, elapsed time: 8.453\n",
      "Imputing row 101/3182 with 0 missing, elapsed time: 8.453\n",
      "Imputing row 201/3182 with 0 missing, elapsed time: 8.456\n",
      "Imputing row 301/3182 with 0 missing, elapsed time: 8.460\n",
      "Imputing row 401/3182 with 0 missing, elapsed time: 8.468\n",
      "Imputing row 501/3182 with 0 missing, elapsed time: 8.470\n",
      "Imputing row 601/3182 with 0 missing, elapsed time: 8.471\n",
      "Imputing row 701/3182 with 4 missing, elapsed time: 8.514\n",
      "Imputing row 801/3182 with 4 missing, elapsed time: 8.532\n",
      "Imputing row 901/3182 with 4 missing, elapsed time: 8.552\n",
      "Imputing row 1001/3182 with 4 missing, elapsed time: 8.572\n",
      "Imputing row 1101/3182 with 4 missing, elapsed time: 8.591\n",
      "Imputing row 1201/3182 with 59 missing, elapsed time: 8.625\n",
      "Imputing row 1301/3182 with 6 missing, elapsed time: 8.669\n",
      "Imputing row 1401/3182 with 6 missing, elapsed time: 8.696\n",
      "Imputing row 1501/3182 with 6 missing, elapsed time: 8.720\n",
      "Imputing row 1601/3182 with 6 missing, elapsed time: 8.746\n",
      "Imputing row 1701/3182 with 6 missing, elapsed time: 8.772\n",
      "Imputing row 1801/3182 with 60 missing, elapsed time: 8.802\n",
      "Imputing row 1901/3182 with 1 missing, elapsed time: 8.847\n",
      "Imputing row 2001/3182 with 1 missing, elapsed time: 8.861\n",
      "Imputing row 2101/3182 with 1 missing, elapsed time: 8.872\n",
      "Imputing row 2201/3182 with 1 missing, elapsed time: 8.878\n",
      "Imputing row 2301/3182 with 1 missing, elapsed time: 8.887\n",
      "Imputing row 2401/3182 with 1 missing, elapsed time: 8.897\n",
      "Imputing row 2501/3182 with 1 missing, elapsed time: 8.909\n",
      "Imputing row 2601/3182 with 2 missing, elapsed time: 8.959\n",
      "Imputing row 2701/3182 with 2 missing, elapsed time: 8.968\n",
      "Imputing row 2801/3182 with 2 missing, elapsed time: 8.978\n",
      "Imputing row 2901/3182 with 2 missing, elapsed time: 8.989\n",
      "Imputing row 3001/3182 with 2 missing, elapsed time: 9.000\n",
      "Imputing row 3101/3182 with 2 missing, elapsed time: 9.010\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "X=X.as_matrix()\n",
    "\n",
    "#Imput missing values from three closest observations\n",
    "X_imputed=KNN(k=3).complete(X)\n",
    "X=pd.DataFrame(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>958.307692</td>\n",
       "      <td>17.827742</td>\n",
       "      <td>52.0</td>\n",
       "      <td>403.673077</td>\n",
       "      <td>79.999452</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.666667</td>\n",
       "      <td>144.039804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>962.019608</td>\n",
       "      <td>14.772112</td>\n",
       "      <td>51.0</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>81.200068</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>866.634831</td>\n",
       "      <td>146.493457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>920006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0     2.0                958.307692                17.827742   \n",
       "1     2.0                958.307692                17.827742   \n",
       "2     2.0                962.019608                14.772112   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              52.0                  403.673077                  79.999452   \n",
       "1              52.0                  403.673077                  79.999452   \n",
       "2              51.0                  415.000000                  81.200068   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              52.0                            0.0   \n",
       "1                              52.0                            0.0   \n",
       "2                              51.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std      ...        \\\n",
       "0                867.666667               144.039804      ...         \n",
       "1                867.666667               144.039804      ...         \n",
       "2                866.634831               146.493457      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               0.0       0.0       0.0         0.0   \n",
       "1                               0.0       0.0       0.0         0.0   \n",
       "2                               0.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct     start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  919991.0            1.0            1.0  \n",
       "1         0.0  919991.0            1.0            1.0  \n",
       "2         0.0  920006.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header values in a list, will be used later to re-label the matrix post KNN imputation\n",
    "dftrain_header = list(df_train.columns.values)\n",
    "X.columns = dftrain_header\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Labels in a new 'Y' DataFrame\n",
    "Y = pd.DataFrame()\n",
    "Y = X['GTcons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1014\n",
       "1.0    1378\n",
       "0.0     790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of labels\n",
    "pd.value_counts(Y.values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove labels from feature set\n",
    "X.drop(['GTcons'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X4 = X.reindex_axis(sorted(X.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Machine Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine_learning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Random Forest Classifier **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi_run'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine Number of trees: Out of Bag Error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# Train on 70% of the data and test on 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(oob_score=True) \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OOB prediction of accuracy is: 97.03637180062866%\n"
     ]
    }
   ],
   "source": [
    "print('The OOB prediction of accuracy is: {oob}%'.format(oob=model.oob_score_ * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/matplotlib/axes/_axes.py:545: UserWarning:\n",
      "\n",
      "No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFaCAYAAAA3jtULAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxDC8iYiIJOb/A6PVX9k3NGFrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5c7208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = 150\n",
    "trees = []\n",
    "oob = []\n",
    "for i in range(1, n_estimators):\n",
    "    model.set_params(n_estimators=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    trees += [i]\n",
    "    oob += [model.oob_score_] \n",
    "    \n",
    "    \n",
    "df_oob = pd.DataFrame()\n",
    "df_oob['trees'] = trees\n",
    "df_oob['oob'] = oob\n",
    "\n",
    "\n",
    "plt.plot(trees, oob)\n",
    "\n",
    "plt.xlabel(\"Number of Trees [n_estimators]\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.savefig('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/ins_alldata_6000_trees_oob.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Model Using Optimal Tuning Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=4,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, random_state=4, class_weight=\"balanced\") \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the training subset: 0.994\n",
      "Accuracy score of the training subset: 0.994\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the training subset: {:.3f}'.format(precision_score(y_test, pred, average='micro'))) \n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score of the training subset: {:.3f}'.format(accuracy_score(y_test, pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add original labels and predicted labels back to the original dataframe\n",
    "df_Xtest = pd.DataFrame(X_test)\n",
    "labels = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['predicted_label'] = pred\n",
    "df_Xtest['GTcons'] = df_train['GTcons']\n",
    "df_Xtest['chrom'] = df_train['chrom']\n",
    "df_Xtest['start'] = df_train['start']\n",
    "df_Xtest['end'] = df_train['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['GTcons'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['GTcons'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['GTcons'].replace(2.0, 'Homozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homozygous_Variant      320\n",
       "Heterozygous_Variant    394\n",
       "Homozygous_Reference    241\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_Xtest['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homozygous_Variant      315\n",
       "Heterozygous_Variant    398\n",
       "Homozygous_Reference    242\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_Xtest['predicted_label'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[393   1   0]\n",
      " [  0 241   0]\n",
      " [  5   0 315]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ytest = df_Xtest['GTcons']\n",
    "predict = df_Xtest['predicted_label']\n",
    "print(confusion_matrix(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>398</td>\n",
       "      <td>242</td>\n",
       "      <td>315</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   393                     1   \n",
       "Homozygous_Reference                     0                   241   \n",
       "Homozygous_Variant                       5                     0   \n",
       "All                                    398                   242   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  394  \n",
       "Homozygous_Reference                   0  241  \n",
       "Homozygous_Variant                   315  320  \n",
       "All                                  315  955  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       0.99      1.00      0.99       394\n",
      "Homozygous_Reference       1.00      1.00      1.00       241\n",
      "  Homozygous_Variant       1.00      0.98      0.99       320\n",
      "\n",
      "         avg / total       0.99      0.99      0.99       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Predict\n",
    "\n",
    "Predict labels for test set\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_size.drop(['GTcons'],axis=1, inplace=True)\n",
    "X2 = df_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1039 with 2 missing, elapsed time: 0.847\n",
      "Imputing row 101/1039 with 3 missing, elapsed time: 0.856\n",
      "Imputing row 201/1039 with 1 missing, elapsed time: 0.871\n",
      "Imputing row 301/1039 with 3 missing, elapsed time: 0.883\n",
      "Imputing row 401/1039 with 3 missing, elapsed time: 0.895\n",
      "Imputing row 501/1039 with 2 missing, elapsed time: 0.906\n",
      "Imputing row 601/1039 with 1 missing, elapsed time: 0.924\n",
      "Imputing row 701/1039 with 3 missing, elapsed time: 0.936\n",
      "Imputing row 801/1039 with 2 missing, elapsed time: 0.946\n",
      "Imputing row 901/1039 with 2 missing, elapsed time: 0.958\n",
      "Imputing row 1001/1039 with 2 missing, elapsed time: 0.974\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>Ill250.amb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>977.521739</td>\n",
       "      <td>7.329924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>417.173913</td>\n",
       "      <td>82.969168</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.705882</td>\n",
       "      <td>166.366450</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11649.10345</td>\n",
       "      <td>4516.179216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>873.616352</td>\n",
       "      <td>161.479434</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10858.17647</td>\n",
       "      <td>4360.693980</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33972943.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.656051</td>\n",
       "      <td>164.646068</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10686.04651</td>\n",
       "      <td>4080.610431</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55880548.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                977.521739                 7.329924              23.0   \n",
       "1                  0.000000                 0.000000               0.0   \n",
       "2                  0.000000                 0.000000               0.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  417.173913                  82.969168   \n",
       "1                    0.000000                   0.000000   \n",
       "2                    0.000000                   0.000000   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              23.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std  Ill250.amb_count  \\\n",
       "0                888.705882               166.366450             170.0   \n",
       "1                873.616352               161.479434             159.0   \n",
       "2                879.656051               164.646068             157.0   \n",
       "\n",
       "       ...        pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0      ...                       11649.10345                4516.179216   \n",
       "1      ...                       10858.17647                4360.693980   \n",
       "2      ...                       10686.04651                4080.610431   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              29.0       0.0       0.0         0.0   \n",
       "1                              51.0       0.0       0.0         0.0   \n",
       "2                              43.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0   2986553.0            0.0            0.0  \n",
       "1         0.0  33972943.0            1.0            1.0  \n",
       "2         0.0  55880548.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 175 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_header = list(df_test_size.columns.values)\n",
    "X2.columns = df_test_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>Ill250.amb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>977.521739</td>\n",
       "      <td>7.329924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>417.173913</td>\n",
       "      <td>82.969168</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.705882</td>\n",
       "      <td>166.366450</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11649.10345</td>\n",
       "      <td>4516.179216</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2986553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>873.616352</td>\n",
       "      <td>161.479434</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10858.17647</td>\n",
       "      <td>4360.693980</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33972943.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.656051</td>\n",
       "      <td>164.646068</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10686.04651</td>\n",
       "      <td>4080.610431</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55880548.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                977.521739                 7.329924              23.0   \n",
       "1                  0.000000                 0.000000               0.0   \n",
       "2                  0.000000                 0.000000               0.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  417.173913                  82.969168   \n",
       "1                    0.000000                   0.000000   \n",
       "2                    0.000000                   0.000000   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_orientation  \\\n",
       "0                              23.0                            0.0   \n",
       "1                               0.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "\n",
       "   Ill250.amb_alnScore_mean  Ill250.amb_alnScore_std  Ill250.amb_count  \\\n",
       "0                888.705882               166.366450             170.0   \n",
       "1                873.616352               161.479434             159.0   \n",
       "2                879.656051               164.646068             157.0   \n",
       "\n",
       "       ...        pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0      ...                       11649.10345                4516.179216   \n",
       "1      ...                       10858.17647                4360.693980   \n",
       "2      ...                       10686.04651                4080.610431   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              29.0       0.0       0.0         0.0   \n",
       "1                              51.0       0.0       0.0         0.0   \n",
       "2                              43.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0   2986553.0            0.0            0.0  \n",
       "1         0.0  33972943.0            1.0            1.0  \n",
       "2         0.0  55880548.0            1.0            1.0  \n",
       "\n",
       "[3 rows x 175 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)\n",
    "pred_prob = model.predict_proba(X5)\n",
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_test_size_2['chrom']\n",
    "X5['GTcons'] = df_test_size_2['GTcons']\n",
    "X5['start'] = df_test_size_2['start']\n",
    "X5['end'] = df_test_size_2['end']\n",
    "X5['Size'] = df_test_size_2['Size']\n",
    "X5['GTsupp'] = df_test_size_2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])\n",
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])\n",
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/df_size_sampTest_df1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/df_size_sampTest_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/df_size_sampTest_df2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6['GTcons'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NaN Labels\n",
    "X6 = X6[np.isfinite(X6['GTcons'])]\n",
    "X6 = X6[np.isfinite(X6['predicted_GTcons_label'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[290   3   0]\n",
      " [  2 453   4]\n",
      " [  2  10 275]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.980\n",
      "Accuracy score of the prediction subset: 0.980\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>453</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>3</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>466</td>\n",
       "      <td>294</td>\n",
       "      <td>279</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   453                     2   \n",
       "Homozygous_Reference                     3                   290   \n",
       "Homozygous_Variant                      10                     2   \n",
       "All                                    466                   294   \n",
       "\n",
       "Predicted             Homozygous_Variant   All  \n",
       "True                                            \n",
       "Heterozygous_Variant                   4   459  \n",
       "Homozygous_Reference                   0   293  \n",
       "Homozygous_Variant                   275   287  \n",
       "All                                  279  1039  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat = pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "conf_mat.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/Test_SizeSamp_All_confMatrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Labels with Pred_Prob >=0.9 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>412</td>\n",
       "      <td>245</td>\n",
       "      <td>238</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   412                     0   \n",
       "Homozygous_Reference                     0                   245   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                    412                   245   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  412  \n",
       "Homozygous_Reference                   0  245  \n",
       "Homozygous_Variant                   238  238  \n",
       "All                                  238  895  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "conf_mat = pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "conf_mat.to_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/size_samp/Test_SizeSamp_All_confMatrix_hi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       1.00      1.00      1.00       412\n",
      "Homozygous_Reference       1.00      1.00      1.00       245\n",
      "  Homozygous_Variant       1.00      1.00      1.00       238\n",
      "\n",
      "         avg / total       1.00      1.00      1.00       895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Size Separate Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size Bins\n",
    "bins = [0, 50, 100,300,400,1000,5999,45516]\n",
    "X6['Size'] = X6['Size'].abs()\n",
    "group_names_size = ['0-50', '50-100', '100-300', '300-400', '400-1000', '1000-5999', '6000+']\n",
    "X6['size_bin'] = pd.cut(X6['Size'], bins, labels=group_names_size)\n",
    "\n",
    "#Separate dataframes based on size_bin\n",
    "df_20to50 = X6[X6['size_bin'].str.contains('0-50')]\n",
    "df_50to100 = X6[X6['size_bin'].str.contains('50-100')]\n",
    "df_100to300 = X6[X6['size_bin'].str.contains('100-300')]\n",
    "df_300to400 = X6[X6['size_bin'].str.contains('300-400')]\n",
    "df_400to1000 = X6[X6['size_bin'].str.contains('400-1000')]\n",
    "df_1000to6000 = X6[X6['size_bin'].str.contains('1000-5999')]\n",
    "df_6000 = X6[X6['size_bin'].str.contains('6000+')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>94</td>\n",
       "      <td>61</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    93                     0   \n",
       "Homozygous_Reference                     0                    61   \n",
       "Homozygous_Variant                       1                     0   \n",
       "All                                     94                    61   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   93  \n",
       "Homozygous_Reference                   0   61  \n",
       "Homozygous_Variant                    45   46  \n",
       "All                                   45  200  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrices\n",
    "consensus_GT = df_20to50['GTcons']\n",
    "predict = df_20to50['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.995\n",
      "Accuracy score of the prediction subset: 0.995\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_50to100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>95</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    95                     1   \n",
       "Homozygous_Reference                     0                    47   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                     95                    48   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   96  \n",
       "Homozygous_Reference                   0   47  \n",
       "Homozygous_Variant                    57   57  \n",
       "All                                   57  200  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_50to100['GTcons']\n",
    "predict = df_50to100['predicted_GTcons_label']\n",
    "print('df_50to100')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.995\n",
      "Accuracy score of the prediction subset: 0.995\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_100to300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>86</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    84                     0   \n",
       "Homozygous_Reference                     2                    61   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                     86                    61   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   1   85  \n",
       "Homozygous_Reference                   0   63  \n",
       "Homozygous_Variant                    52   52  \n",
       "All                                   53  200  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_100to300['GTcons']\n",
    "predict = df_100to300['predicted_GTcons_label']\n",
    "print('df_100to300')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.985\n",
      "Accuracy score of the prediction subset: 0.985\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_300to400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>105</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   103                     1   \n",
       "Homozygous_Reference                     0                    55   \n",
       "Homozygous_Variant                       2                     0   \n",
       "All                                    105                    56   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   1  105  \n",
       "Homozygous_Reference                   0   55  \n",
       "Homozygous_Variant                    36   38  \n",
       "All                                   37  198  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_300to400['GTcons']\n",
    "predict = df_300to400['predicted_GTcons_label']\n",
    "print('df_300to400')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.980\n",
      "Accuracy score of the prediction subset: 0.980\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_400to1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    43                     0   \n",
       "Homozygous_Reference                     1                    40   \n",
       "Homozygous_Variant                       2                     1   \n",
       "All                                     46                    41   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   43  \n",
       "Homozygous_Reference                   0   41  \n",
       "Homozygous_Variant                    56   59  \n",
       "All                                   56  143  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_400to1000['GTcons']\n",
    "predict = df_400to1000['predicted_GTcons_label']\n",
    "print('df_400to1000')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.972\n",
      "Accuracy score of the prediction subset: 0.972\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1000to6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    34                     0   \n",
       "Homozygous_Reference                     0                    26   \n",
       "Homozygous_Variant                       4                     1   \n",
       "All                                     38                    27   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   1   35  \n",
       "Homozygous_Reference                   0   26  \n",
       "Homozygous_Variant                    27   32  \n",
       "All                                   28   93  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_1000to6000['GTcons']\n",
    "predict = df_1000to6000['predicted_GTcons_label']\n",
    "print('df_1000to6000')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.935\n",
      "Accuracy score of the prediction subset: 0.935\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_6000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Variant  All\n",
       "True                                                               \n",
       "Heterozygous_Variant                     1                   1    2\n",
       "Homozygous_Variant                       1                   2    3\n",
       "All                                      2                   3    5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = df_6000['GTcons']\n",
    "predict = df_6000['predicted_GTcons_label']\n",
    "print('df_6000')\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.600\n",
      "Accuracy score of the prediction subset: 0.600\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) \n",
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 to 50 bp Hom Var 0.9445652173913043\n",
      "20 to 50 bp Het Var 0.9752688172043014\n",
      "20 to 50 bp Hom Ref 0.9680327868852461\n",
      "50to100 bp Hom Var 0.9657894736842108\n",
      "50to100 bp Het Var 0.9515625000000004\n",
      "50to100 bp Hom Ref 0.9531914893617021\n",
      "100to300 bp Hom Var 0.9596153846153848\n",
      "100to300 bp Het Var 0.9523529411764707\n",
      "100to300 bp Hom Ref 0.9373015873015875\n",
      "300to400 bp Hom Var 0.9184210526315787\n",
      "300to400 bp Het Var 0.9585714285714287\n",
      "300to400 bp Hom Ref 0.9772727272727274\n",
      "400to1000 bp Hom Var 0.8991525423728816\n",
      "400to1000 bp Het Var 0.9418604651162791\n",
      "400to1000 bp Hom Ref 0.9268292682926831\n",
      "1000to6000 bp Hom Var 0.8312499999999999\n",
      "1000to6000 bp Het Var 0.9514285714285714\n",
      "1000to6000 bp Hom Ref 0.8423076923076922\n",
      "6000 bp Hom Var 0.8166666666666668\n",
      "6000 bp Het Var 0.625\n",
      "6000 bp Hom Ref nan\n"
     ]
    }
   ],
   "source": [
    "#Calculate average pred prob for each group\n",
    "df_20to50_homVar = df_20to50[df_20to50['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_20to50_hetVar = df_20to50[df_20to50['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_20to50_homRef = df_20to50[df_20to50['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_20to50_homVar.mean()\n",
    "df_20to50_hetVar.mean()\n",
    "df_20to50_homRef.mean()\n",
    "print('20 to 50 bp Hom Var {}'.format(df_20to50_homVar.mean())) \n",
    "print('20 to 50 bp Het Var {}'.format(df_20to50_hetVar.mean())) \n",
    "print('20 to 50 bp Hom Ref {}'.format(df_20to50_homRef.mean())) \n",
    "\n",
    "df_50to100_homVar = df_50to100[df_50to100['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_50to100_hetVar = df_50to100[df_50to100['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_50to100_homRef = df_50to100[df_50to100['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_50to100_homVar.mean()\n",
    "df_50to100_hetVar.mean()\n",
    "df_50to100_homRef.mean()\n",
    "print('50to100 bp Hom Var {}'.format(df_50to100_homVar.mean())) \n",
    "print('50to100 bp Het Var {}'.format(df_50to100_hetVar.mean())) \n",
    "print('50to100 bp Hom Ref {}'.format(df_50to100_homRef.mean())) \n",
    "\n",
    "df_100to300_homVar = df_100to300[df_100to300['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_100to300_hetVar = df_100to300[df_100to300['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_100to300_homRef = df_100to300[df_100to300['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_100to300_homVar.mean()\n",
    "df_100to300_hetVar.mean()\n",
    "df_100to300_homRef.mean()\n",
    "print('100to300 bp Hom Var {}'.format(df_100to300_homVar.mean())) \n",
    "print('100to300 bp Het Var {}'.format(df_100to300_hetVar.mean())) \n",
    "print('100to300 bp Hom Ref {}'.format(df_100to300_homRef.mean())) \n",
    "\n",
    "df_300to400_homVar = df_300to400[df_300to400['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_300to400_hetVar = df_300to400[df_300to400['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_300to400_homRef = df_300to400[df_300to400['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_300to400_homVar.mean()\n",
    "df_300to400_hetVar.mean()\n",
    "df_300to400_homRef.mean()\n",
    "print('300to400 bp Hom Var {}'.format(df_300to400_homVar.mean())) \n",
    "print('300to400 bp Het Var {}'.format(df_300to400_hetVar.mean())) \n",
    "print('300to400 bp Hom Ref {}'.format(df_300to400_homRef.mean())) \n",
    "\n",
    "df_400to1000_homVar = df_400to1000[df_400to1000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_400to1000_hetVar = df_400to1000[df_400to1000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_400to1000_homRef = df_400to1000[df_400to1000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_400to1000_homVar.mean()\n",
    "df_400to1000_hetVar.mean()\n",
    "df_400to1000_homRef.mean()\n",
    "print('400to1000 bp Hom Var {}'.format(df_400to1000_homVar.mean())) \n",
    "print('400to1000 bp Het Var {}'.format(df_400to1000_hetVar.mean())) \n",
    "print('400to1000 bp Hom Ref {}'.format(df_400to1000_homRef.mean())) \n",
    "\n",
    "df_1000to6000_homVar = df_1000to6000[df_1000to6000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_1000to6000_hetVar = df_1000to6000[df_1000to6000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_1000to6000_homRef = df_1000to6000[df_1000to6000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_1000to6000_homVar.mean()\n",
    "df_1000to6000_hetVar.mean()\n",
    "df_1000to6000_homRef.mean()\n",
    "print('1000to6000 bp Hom Var {}'.format(df_1000to6000_homVar.mean())) \n",
    "print('1000to6000 bp Het Var {}'.format(df_1000to6000_hetVar.mean())) \n",
    "print('1000to6000 bp Hom Ref {}'.format(df_1000to6000_homRef.mean())) \n",
    "\n",
    "df_6000_homVar = df_6000[df_6000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_6000_hetVar = df_6000[df_6000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_6000_homRef = df_6000[df_6000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_6000_homVar.mean()\n",
    "df_6000_hetVar.mean()\n",
    "df_6000_homRef.mean()\n",
    "print('6000 bp Hom Var {}'.format(df_6000_homVar.mean())) \n",
    "print('6000 bp Het Var {}'.format(df_6000_hetVar.mean())) \n",
    "print('6000 bp Hom Ref {}'.format(df_6000_homRef.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minus 1 Analysis\n",
    "X6 = pd.read_csv('/Volumes/lesleydata/size_sample/Step4_ML/plots/INS/all_data/5k_Test_Set/6000_train/dataframes/df_alldata_6000_min1_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Size Bins\n",
    "bins = [0, 50, 100,300,400,1000,5999,45516]\n",
    "X6['Size'] = X6['Size'].abs()\n",
    "group_names_size = ['0-50', '50-100', '100-300', '300-400', '400-1000', '1000-5999', '6000+']\n",
    "X6['size_bin'] = pd.cut(X6['Size'], bins, labels=group_names_size)\n",
    "\n",
    "\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)\n",
    "\n",
    "X6['GTcons'] = X6['predicted_GTcons_label']\n",
    "\n",
    "#Separate dataframes based on size_bin\n",
    "df_20to50 = X6[X6['size_bin'].str.contains('0-50')]\n",
    "df_50to100 = X6[X6['size_bin'].str.contains('50-100')]\n",
    "df_100to300 = X6[X6['size_bin'].str.contains('100-300')]\n",
    "df_300to400 = X6[X6['size_bin'].str.contains('300-400')]\n",
    "df_400to1000 = X6[X6['size_bin'].str.contains('400-1000')]\n",
    "df_1000to6000 = X6[X6['size_bin'].str.contains('1000-5999')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-5999    586\n",
       "400-1000     367\n",
       "100-300      352\n",
       "50-100       334\n",
       "0-50         279\n",
       "300-400      130\n",
       "6000+          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(X6['size_bin'].values, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 to 50 bp Hom Var 0.7948818897637798\n",
      "20 to 50 bp Het Var 0.7307692307692308\n",
      "20 to 50 bp Hom Ref 0.7283783783783782\n",
      "50to100 bp Hom Var 0.7782178217821785\n",
      "50to100 bp Het Var 0.7436936936936934\n",
      "50to100 bp Hom Ref 0.7282786885245902\n",
      "100to300 bp Hom Var 0.8045081967213119\n",
      "100to300 bp Het Var 0.7812500000000003\n",
      "100to300 bp Hom Ref 0.7559859154929577\n",
      "300to400 bp Hom Var 0.8590163934426228\n",
      "300to400 bp Het Var 0.7400000000000001\n",
      "300to400 bp Hom Ref 0.7926470588235294\n",
      "400to1000 bp Hom Var 0.8111111111111118\n",
      "400to1000 bp Het Var 0.6934782608695651\n",
      "400to1000 bp Hom Ref 0.7846625766871161\n",
      "1000to6000 bp Hom Var 0.7611111111111108\n",
      "1000to6000 bp Het Var 0.7240384615384621\n",
      "1000to6000 bp Hom Ref 0.7282511210762328\n"
     ]
    }
   ],
   "source": [
    "#Calculate average pred prob for each group\n",
    "df_20to50_homVar = df_20to50[df_20to50['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_20to50_hetVar = df_20to50[df_20to50['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_20to50_homRef = df_20to50[df_20to50['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_20to50_homVar.mean()\n",
    "df_20to50_hetVar.mean()\n",
    "df_20to50_homRef.mean()\n",
    "print('20 to 50 bp Hom Var {}'.format(df_20to50_homVar.mean())) \n",
    "print('20 to 50 bp Het Var {}'.format(df_20to50_hetVar.mean())) \n",
    "print('20 to 50 bp Hom Ref {}'.format(df_20to50_homRef.mean())) \n",
    "\n",
    "df_50to100_homVar = df_50to100[df_50to100['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_50to100_hetVar = df_50to100[df_50to100['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_50to100_homRef = df_50to100[df_50to100['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_50to100_homVar.mean()\n",
    "df_50to100_hetVar.mean()\n",
    "df_50to100_homRef.mean()\n",
    "print('50to100 bp Hom Var {}'.format(df_50to100_homVar.mean())) \n",
    "print('50to100 bp Het Var {}'.format(df_50to100_hetVar.mean())) \n",
    "print('50to100 bp Hom Ref {}'.format(df_50to100_homRef.mean())) \n",
    "\n",
    "df_100to300_homVar = df_100to300[df_100to300['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_100to300_hetVar = df_100to300[df_100to300['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_100to300_homRef = df_100to300[df_100to300['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_100to300_homVar.mean()\n",
    "df_100to300_hetVar.mean()\n",
    "df_100to300_homRef.mean()\n",
    "print('100to300 bp Hom Var {}'.format(df_100to300_homVar.mean())) \n",
    "print('100to300 bp Het Var {}'.format(df_100to300_hetVar.mean())) \n",
    "print('100to300 bp Hom Ref {}'.format(df_100to300_homRef.mean())) \n",
    "\n",
    "df_300to400_homVar = df_300to400[df_300to400['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_300to400_hetVar = df_300to400[df_300to400['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_300to400_homRef = df_300to400[df_300to400['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_300to400_homVar.mean()\n",
    "df_300to400_hetVar.mean()\n",
    "df_300to400_homRef.mean()\n",
    "print('300to400 bp Hom Var {}'.format(df_300to400_homVar.mean())) \n",
    "print('300to400 bp Het Var {}'.format(df_300to400_hetVar.mean())) \n",
    "print('300to400 bp Hom Ref {}'.format(df_300to400_homRef.mean())) \n",
    "\n",
    "df_400to1000_homVar = df_400to1000[df_400to1000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_400to1000_hetVar = df_400to1000[df_400to1000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_400to1000_homRef = df_400to1000[df_400to1000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_400to1000_homVar.mean()\n",
    "df_400to1000_hetVar.mean()\n",
    "df_400to1000_homRef.mean()\n",
    "print('400to1000 bp Hom Var {}'.format(df_400to1000_homVar.mean())) \n",
    "print('400to1000 bp Het Var {}'.format(df_400to1000_hetVar.mean())) \n",
    "print('400to1000 bp Hom Ref {}'.format(df_400to1000_homRef.mean())) \n",
    "\n",
    "df_1000to6000_homVar = df_1000to6000[df_1000to6000['GTcons'] == 'Homozygous_Variant']['Homozygous_Variant_GTcons']\n",
    "df_1000to6000_hetVar = df_1000to6000[df_1000to6000['GTcons'] == 'Heterozygous_Variant']['Heterozygous_Variant_GTcons']\n",
    "df_1000to6000_homRef = df_1000to6000[df_1000to6000['GTcons'] == 'Homozygous_Reference']['Homozygous_Reference_GTcons']\n",
    "\n",
    "df_1000to6000_homVar.mean()\n",
    "df_1000to6000_hetVar.mean()\n",
    "df_1000to6000_homRef.mean()\n",
    "print('1000to6000 bp Hom Var {}'.format(df_1000to6000_homVar.mean())) \n",
    "print('1000to6000 bp Het Var {}'.format(df_1000to6000_hetVar.mean())) \n",
    "print('1000to6000 bp Hom Ref {}'.format(df_1000to6000_homRef.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
