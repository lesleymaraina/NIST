{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML_RF_SizeStratify_randomsample\n",
    "* Machine Learning Training Data : size stratification\n",
    "* Data originally pooled from all technologies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import io\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import plotly.plotly as py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "from bokeh.charts import TimeSeries\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.charts import Scatter, Histogram, output_file, show\n",
    "from bokeh.plotting import figure, show, output_file, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "import bokeh.palettes as palettes\n",
    "from bokeh.models import HoverTool, BoxSelectTool, Legend\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data - weight based on consensus genotype\n",
    "df_train = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/train/random_sample_AllData_szwt_train.csv')\n",
    "df_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/test/random_sample_AllData_szwt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the data\n",
    "df_train_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/train/random_sample_AllData_szwt_train.csv')\n",
    "df_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/test/random_sample_AllData_szwt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop select columns [categorical data and columns that would bias the model]\n",
    "df_train.drop(['index'], axis=1, inplace = True)\n",
    "df_train.drop(['id'], axis=1, inplace = True)\n",
    "df_train.drop(['New_ID'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_train.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_train.drop(['sample'], axis=1, inplace = True)\n",
    "df_train.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_train.drop(['type'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change class label from categorical to numerical\n",
    "df_train['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_train['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_train['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop select columns [categorical data and columns that would bias the model]\n",
    "df_test.drop(['index'], axis=1, inplace = True)\n",
    "df_test.drop(['id'], axis=1, inplace = True)\n",
    "df_test.drop(['New_ID'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_test.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_test.drop(['sample'], axis=1, inplace = True)\n",
    "df_test.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_test.drop(['type'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change class label from categorical to numerical\n",
    "df_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Training Data\n",
    "df_20to49 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_20to49_train_.csv')\n",
    "df_50to99 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_50to99_train_.csv')\n",
    "df_100to299 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_100to299_train_.csv')\n",
    "df_300to399 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_300to399_train_.csv')\n",
    "df_400to499 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_400to499_train_.csv')\n",
    "df_500to999 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_500to999_train_.csv')\n",
    "df_1000to5999 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_1000to5999_train_.csv')\n",
    "df_6000 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_6000_train_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy Dataframes for later parsing tasks\n",
    "df_20to49_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_20to49_train.csv')\n",
    "df_50to99_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_50to99_train.csv')\n",
    "df_100to299_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_100to299_train.csv')\n",
    "df_300to399_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_300to399_train.csv')\n",
    "df_400to499_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_400to499_train.csv')\n",
    "df_500to999_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_500to999_train.csv')\n",
    "df_1000to5999_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_1000to5999_train.csv')\n",
    "df_6000_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_6000_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_20to49['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_20to49['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_50to99['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_50to99['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_50to99['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_100to299['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_100to299['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_100to299['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_300to399['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_300to399['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_300to399['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_400to499['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_400to499['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_400to499['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_500to999['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_500to999['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_500to999['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_1000to5999['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_1000to5999['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_1000to5999['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_6000['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_6000['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_6000['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hom_ref'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Test Data\n",
    "df_20to49_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_20to49_test_.csv')\n",
    "df_50to99_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_50to99_test_.csv')\n",
    "df_100to299_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_100to299_test_.csv')\n",
    "df_300to399_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_300to399_test_.csv')\n",
    "df_400to499_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_400to499_test_.csv')\n",
    "df_500to999_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_500to999_test_.csv')\n",
    "df_1000to5999_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_1000to5999_test_.csv')\n",
    "df_6000_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_6000_test_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Test Data\n",
    "df_20to49_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_20to49_test.csv')\n",
    "df_50to99_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_50to99_test.csv')\n",
    "df_100to299_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_100to299_test.csv')\n",
    "df_300to399_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_300to399_test.csv')\n",
    "df_400to499_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_400to499_test.csv')\n",
    "df_500to999_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_500to999_test.csv')\n",
    "df_1000to5999_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_1000to5999_test.csv')\n",
    "df_6000_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_6000_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_20to49_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_20to49_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_50to99_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_50to99_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_50to99_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_100to299_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_100to299_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_100to299_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_300to399_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_300to399_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_300to399_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_400to499_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_400to499_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_400to499_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_500to999_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_500to999_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_500to999_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_1000to5999_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_1000to5999_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_1000to5999_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_6000_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_6000_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_6000_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_20to49_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_20to49_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_50to99_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_50to99_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_50to99_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_100to299_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_100to299_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_100to299_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_300to399_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_300to399_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_300to399_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_400to499_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_400to499_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_400to499_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_500to999_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_500to999_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_500to999_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_1000to5999_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_1000to5999_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_1000to5999_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_6000_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_6000_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_6000_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Store header names in lists and find names that are NOT contained in BOTH lists\n",
    "# c = list(df_train.columns.values)\n",
    "# d = list(df_test.columns.values)\n",
    "# set(d) - set(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "EDA\n",
    "\n",
    "Size distribution of sampled data set [all size datasets pooled]\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/train/random_sample_SizeBins_szwt_train.csv')\n",
    "# df_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/test/random_sample_SizeBins_szwt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Load data\n",
    "# df_train = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/train/random_sample_tSNE_train.csv')\n",
    "# df_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/test/random_sample_tSNE_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_train['Size'] = df_train['Size'].abs()\n",
    "# df_test['Size'] = df_test['Size'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_train['Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_train = df_train[df_train['Size'] >= 20]\n",
    "# df_test = df_test[df_test['Size'] >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['log_size'] = np.log10(df_train.Size)\n",
    "# df_test['log_size'] = np.log10(df_test.Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.set_style(\"white\")\n",
    "# p = df_train['log_size'].hist(alpha = 0.5, bins = 30, edgecolor='black', label='hom_var')\n",
    "# p.grid(False)\n",
    "# p.set_xlabel('Size[log10]')\n",
    "# p.set_ylabel('Frequency')\n",
    "# p.set_title('Training Set')\n",
    "# # plt.show()\n",
    "# plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/random_sample_SizeDist_training.png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.set_style(\"white\")\n",
    "# p = df_test['log_size'].hist(alpha = 0.5, bins = 30, edgecolor='black', label='hom_var')\n",
    "# p.grid(False)\n",
    "# p.set_xlabel('Size[log10]')\n",
    "# p.set_ylabel('Frequency')\n",
    "# p.set_title('Test Set')\n",
    "# # plt.show()\n",
    "# plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/random_sample_SizeDist_test.png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Random Sample Data**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Impute missing values using KNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2750, 177)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training data in a new variable which will be converted to a matrix\n",
    "X = df_train\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/2750 with 2 missing, elapsed time: 7.226\n",
      "Imputing row 101/2750 with 2 missing, elapsed time: 7.286\n",
      "Imputing row 201/2750 with 1 missing, elapsed time: 7.301\n",
      "Imputing row 301/2750 with 2 missing, elapsed time: 7.318\n",
      "Imputing row 401/2750 with 1 missing, elapsed time: 7.344\n",
      "Imputing row 501/2750 with 2 missing, elapsed time: 7.360\n",
      "Imputing row 601/2750 with 2 missing, elapsed time: 7.372\n",
      "Imputing row 701/2750 with 1 missing, elapsed time: 7.392\n",
      "Imputing row 801/2750 with 2 missing, elapsed time: 7.415\n",
      "Imputing row 901/2750 with 1 missing, elapsed time: 7.427\n",
      "Imputing row 1001/2750 with 1 missing, elapsed time: 7.448\n",
      "Imputing row 1101/2750 with 1 missing, elapsed time: 7.461\n",
      "Imputing row 1201/2750 with 1 missing, elapsed time: 7.472\n",
      "Imputing row 1301/2750 with 1 missing, elapsed time: 7.485\n",
      "Imputing row 1401/2750 with 2 missing, elapsed time: 7.502\n",
      "Imputing row 1501/2750 with 1 missing, elapsed time: 7.514\n",
      "Imputing row 1601/2750 with 1 missing, elapsed time: 7.530\n",
      "Imputing row 1701/2750 with 2 missing, elapsed time: 7.554\n",
      "Imputing row 1801/2750 with 2 missing, elapsed time: 7.567\n",
      "Imputing row 1901/2750 with 1 missing, elapsed time: 7.581\n",
      "Imputing row 2001/2750 with 2 missing, elapsed time: 7.592\n",
      "Imputing row 2101/2750 with 2 missing, elapsed time: 7.612\n",
      "Imputing row 2201/2750 with 1 missing, elapsed time: 7.630\n",
      "Imputing row 2301/2750 with 2 missing, elapsed time: 7.642\n",
      "Imputing row 2401/2750 with 2 missing, elapsed time: 7.661\n",
      "Imputing row 2501/2750 with 1 missing, elapsed time: 7.674\n",
      "Imputing row 2601/2750 with 1 missing, elapsed time: 7.691\n",
      "Imputing row 2701/2750 with 2 missing, elapsed time: 7.713\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "X=X.as_matrix()\n",
    "\n",
    "#Imput missing values from three closest observations\n",
    "X_imputed=KNN(k=3).complete(X)\n",
    "X=pd.DataFrame(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>954.066667</td>\n",
       "      <td>22.758051</td>\n",
       "      <td>30.0</td>\n",
       "      <td>459.933333</td>\n",
       "      <td>89.138444</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>871.251462</td>\n",
       "      <td>...</td>\n",
       "      <td>10246.87500</td>\n",
       "      <td>3592.008063</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3411962.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>974.920000</td>\n",
       "      <td>12.958148</td>\n",
       "      <td>25.0</td>\n",
       "      <td>434.480000</td>\n",
       "      <td>72.814350</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.165803</td>\n",
       "      <td>...</td>\n",
       "      <td>9156.50000</td>\n",
       "      <td>4929.774990</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61058056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.043206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>986.695652</td>\n",
       "      <td>8.253773</td>\n",
       "      <td>23.0</td>\n",
       "      <td>454.956522</td>\n",
       "      <td>64.583265</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>891.564444</td>\n",
       "      <td>...</td>\n",
       "      <td>10098.75862</td>\n",
       "      <td>3684.034517</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11556162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0     1.0                954.066667                22.758051   \n",
       "1     1.0                974.920000                12.958148   \n",
       "2     1.0                986.695652                 8.253773   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              30.0                  459.933333                  89.138444   \n",
       "1              25.0                  434.480000                  72.814350   \n",
       "2              23.0                  454.956522                  64.583265   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                              30.0                                0.0   \n",
       "1                              24.0                                1.0   \n",
       "2                              23.0                                0.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean      ...        \\\n",
       "0                            0.0                871.251462      ...         \n",
       "1                            0.0                888.165803      ...         \n",
       "2                            0.0                891.564444      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                 10246.87500                3592.008063   \n",
       "1                  9156.50000                4929.774990   \n",
       "2                 10098.75862                3684.034517   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              32.0       0.0       0.0         0.0   \n",
       "1                              20.0       0.0       0.0         0.0   \n",
       "2                              29.0       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0   3411962.0            1.0       1.000000  \n",
       "1         0.0  61058056.0            3.0       0.043206  \n",
       "2         0.0  11556162.0            1.0       1.000000  \n",
       "\n",
       "[3 rows x 177 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header values in a list, will be used later to re-label the matrix post KNN imputation\n",
    "df_train_header = list(df_train.columns.values)\n",
    "X.columns = df_train_header\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Labels in a new 'Y' DataFrame\n",
    "Y = pd.DataFrame()\n",
    "Y = X['GTcons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1373\n",
       "0.0     832\n",
       "2.0     545\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of labels\n",
    "pd.value_counts(Y.values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove labels from feature set\n",
    "X.drop(['GTcons'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X4 = X.reindex_axis(sorted(X.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Machine Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine_learning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Random Forest Classifier **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi_run'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine Number of trees: Out of Bag Error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# Train on 70% of the data and test on 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(oob_score=True, class_weight='balanced') \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE :** \n",
    "\n",
    "Determined OOB score based on 70% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:453: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 150\n",
    "trees = []\n",
    "oob = []\n",
    "for i in range(1, n_estimators):\n",
    "    model.set_params(n_estimators=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    trees += [i]\n",
    "    oob += [model.oob_score_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_oob = pd.DataFrame()\n",
    "# df_oob['trees'] = trees\n",
    "# df_oob['oob'] = oob\n",
    "\n",
    "# ax = plt.plot(trees, oob)\n",
    "# sns.set_style(\"white\")\n",
    "# plt.xlabel(\"Number of Trees [n_estimators]\")\n",
    "# plt.ylim((0,1))\n",
    "# plt.ylabel(\"OOB error rate\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/random_sample_OOB.png', bbox_inches='tight')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Model Using Optimal Tuning Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=18, n_jobs=1, oob_score=False, random_state=4,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=18, random_state=4, class_weight=\"balanced\") \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Another Resource](https://stackoverflow.com/questions/37877542/how-to-label-the-feature-importance-with-forests-of-trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='100_trees'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/ipykernel/__main__.py:3: FutureWarning:\n",
      "\n",
      "sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # %matplotlib inline\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "feature_importances.sort()\n",
    "feature_importances.plot(kind=\"barh\", figsize=(8,30))\n",
    "plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/df_random_sample_featureImportance.png', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/random_sample_feature_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = X4[['pacbio.alt_reason_alignmentScore','pacbio.alt_insertSize_std','pacbio.ref_alnScore_std','Ill300x.ref_reason_alignmentScore','Ill300x.alt_count','pacbio.ref_reason_alignmentScore','pacbio.ref_insertSize_std','pacbio.alt_alnScore_std','pacbio.ref_count','Ill250.alt_count','pacbio.alt_count','pacbio.ref_insertSize_mean','Ill250.alt_alnScore_mean','Ill250.alt_alnScore_std','TenX.HP2_alt_count','pacbio.alt_insertSize_mean','Ill250.ref_reason_alignmentScore','Ill250.alt_reason_alignmentScore','IllMP.alt_alnScore_mean','IllMP.ref_count','pacbio.ref_alnScore_mean','TenX.HP1_ref_insertSize_std','Ill300x.ref_count','TenX.HP2_alt_reason_alignmentScore','IllMP.ref_alnScore_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(X_.corr(), annot=True, fmt=\".2f\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.yticks(rotation='horizontal')\n",
    "# plt.figure(figsize=(18, 18))\n",
    "#  plt.show()\n",
    "plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/df_random_sample_heatmap.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Training Set - Show number of Hom Ref, Hom Var, Het Var datapoints the model was trained on\n",
    "ytrain = pd.DataFrame()\n",
    "ytrain['ytrain'] = y_train\n",
    "pd.value_counts(ytrain['ytrain'].values, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='traintest_precision'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of the training subset: {:.3f}'.format(precision_score(y_test, pred, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score of the training subset: {:.3f}'.format(accuracy_score(y_test, pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add original labels and predicted labels back to the original dataframe\n",
    "df_Xtest = pd.DataFrame(X_test)\n",
    "df_Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['predicted_label'] = pred\n",
    "df_Xtest['GTcons'] = df_train['GTcons']\n",
    "df_Xtest['chrom'] = df_train['chrom']\n",
    "df_Xtest['start'] = df_train['start']\n",
    "df_Xtest['end'] = df_train['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['GTcons'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['GTcons'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['GTcons'].replace(2.0, 'Homozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df_Xtest['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df_Xtest['predicted_label'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_Xtest['predicted_label'] = df_Xtest['predicted_label'].astype(str)\n",
    "# df_Xtest['GTcons'] = df_Xtest['GTcons'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ytest = df_Xtest['GTcons']\n",
    "predict = df_Xtest['predicted_label']\n",
    "print(confusion_matrix(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='traintest_confusion_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Pandas: save table to HTML\n",
    "# p = pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "# p.to_html('cro.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model with all samples in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=20, random_state=4, class_weight=\"balanced\") \n",
    "# model.fit(X4, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Predict\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.drop(['GTcons'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X2_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_header = list(df_test.columns.values)\n",
    "X2.columns = df_test_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_test_['chrom']\n",
    "X5['GTcons'] = df_test_['GTcons']\n",
    "X5['start'] = df_test_['start']\n",
    "X5['end'] = df_test_['end']\n",
    "X5['Size'] = df_test_['Size']\n",
    "# X5['GTsupp'] = df_6000_test_['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/df_random_sample_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/df_random_sample_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/df_random_sample_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/df_random_sample_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X7['GTcons'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO:** Find out why the following dataframes give low scores. Probably a parsing problem</font>\n",
    "    \n",
    "    * 50-99\n",
    "    * 100-299\n",
    "    * 400-499\n",
    "    * 500-999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 50-99\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 50-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_50to99 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_50to99_test_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_50to99, df_50to99_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df_ = pd.concat([df_50to99_, df_50to99_test_], axis=0)\n",
    "df_ = df_.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'], axis=1, inplace = True)\n",
    "df_.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = list(df_train.columns.values)\n",
    "d = list(df.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df_.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_['chrom']\n",
    "X5['GTcons'] = df_['GTcons']\n",
    "X5['start'] = df_['start']\n",
    "X5['end'] = df_['end']\n",
    "X5['Size'] = df_['Size']\n",
    "X5['GTsupp'] = df_['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/tsne/50to99_predLrg_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/tsne/50to99_log._predLrgcsv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/tsne/50to99_predLrg_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/tsne/50to99_final_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 100 - 299 bp\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 100 - 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_100to299, df_100to299_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = pd.concat([df_100to299_, df_100to299_test_], axis=0)\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df2['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df2['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "# df['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "# df['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "# df['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df2.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df2['chrom']\n",
    "X5['GTcons'] = df2['GTcons']\n",
    "X5['start'] = df2['start']\n",
    "X5['end'] = df2['end']\n",
    "X5['Size'] = df2['Size']\n",
    "# X5['GTsupp'] = df['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/100to299_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/all_log_100to299_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/100to299_predLrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/500to999_final_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 500 - 999 bp\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 500 - 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_500to999, df_500to999_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = pd.concat([df_500to999_, df_500to999_test_], axis=0)\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df2['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df2['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "# df['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "# df['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "# df['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df2.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df2['chrom']\n",
    "X5['GTcons'] = df2['GTcons']\n",
    "X5['start'] = df2['start']\n",
    "X5['end'] = df2['end']\n",
    "X5['Size'] = df2['Size']\n",
    "# X5['GTsupp'] = df['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/500to999_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/all_log_500to999_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/500to999_predLrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/all/500to999_final_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 1000to5999\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 1000to5999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_1000to5999, df_1000to5999_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = pd.concat([df_1000to5999, df_1000to5999_test], axis=0)\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(df_train.columns.values)\n",
    "d = list(df.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df2.drop(['index'],axis=1, inplace=True)\n",
    "# df.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)\n",
    "# df2.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df2['chrom']\n",
    "X5['GTcons'] = df2['GTcons']\n",
    "X5['start'] = df2['start']\n",
    "X5['end'] = df2['end']\n",
    "X5['Size'] = df2['Size']\n",
    "# X5['GTsupp'] = df2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/1000to5999_random_sample_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/1000to5999_log_random_sample_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/1000to5999_random_sample_predLrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/1000to5999_final_random_sample_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 300to399\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 300to399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_300to399, df_300to399_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = pd.concat([df_300to399, df_300to399_test], axis=0)\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(df_train.columns.values)\n",
    "d = list(df.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df2.drop(['index'],axis=1, inplace=True)\n",
    "# df.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)\n",
    "# df2.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df2['chrom']\n",
    "X5['GTcons'] = df2['GTcons']\n",
    "X5['start'] = df2['start']\n",
    "X5['end'] = df2['end']\n",
    "X5['Size'] = df2['Size']\n",
    "# X5['GTsupp'] = df2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/300to399_random_sample_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/300to399_log_random_sample_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/300to399_random_sample_predLrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/300to399_final_random_sample_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 6000+ bp\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 6000+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_6000, df_6000_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = pd.concat([df_6000, df_6000_test], axis=0)\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(df_train.columns.values)\n",
    "d = list(df.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df2.drop(['index'],axis=1, inplace=True)\n",
    "# df.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)\n",
    "# df2.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df2['chrom']\n",
    "X5['GTcons'] = df2['GTcons']\n",
    "X5['start'] = df2['start']\n",
    "X5['end'] = df2['end']\n",
    "X5['Size'] = df2['Size']\n",
    "# X5['GTsupp'] = df2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/6000_random_sample_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/6000_log_random_sample_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/6000_random_sample_predLrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/6000_final_random_sample_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 20 to 49bp\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 20 to 49bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_20to49, df_20to49_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = pd.concat([df_20to49, df_20to49_test], axis=0)\n",
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(df_train.columns.values)\n",
    "d = list(df.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df2.drop(['index'],axis=1, inplace=True)\n",
    "# df.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)\n",
    "# df2.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df2['chrom']\n",
    "X5['GTcons'] = df2['GTcons']\n",
    "X5['start'] = df2['start']\n",
    "X5['end'] = df2['end']\n",
    "X5['Size'] = df2['Size']\n",
    "# X5['GTsupp'] = df2['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/20to49_random_sample_predsm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/6000_log_20to49_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/20to49_random_sample_predsm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/random_sample/20to49_random_sample_final_predsm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
