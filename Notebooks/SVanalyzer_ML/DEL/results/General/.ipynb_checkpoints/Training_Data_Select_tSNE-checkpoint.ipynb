{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data: Consensus Genotype\n",
    "\n",
    "* The following notebook is trained on data generated from revised R script [Oct 12 2017]\n",
    "    * Exact Match [1] and Homozygous [0] Reference data points\n",
    "    * Removed all data points with Gtcons and GTconswithoutXX -1\n",
    "* 5k randomly selected deletions test data was also processed through same R script\n",
    "* Balanced Training Set for GTcons labels:\n",
    "    * 200 Hom Var\n",
    "    * 200 Hom Ref\n",
    "    * 200 Het Var\n",
    "* **Train/Prediction Label:** consensus genotype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import io\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import plotly.plotly as py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "from bokeh.charts import TimeSeries\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.charts import Scatter, Histogram, output_file, show\n",
    "from bokeh.plotting import figure, show, output_file, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "import bokeh.palettes as palettes\n",
    "from bokeh.models import HoverTool, BoxSelectTool, Legend\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>id</th>\n",
       "      <th>sample</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>SVtype</th>\n",
       "      <th>Size</th>\n",
       "      <th>Ill250.GT</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "      <th>Label</th>\n",
       "      <th>GTconflict</th>\n",
       "      <th>GTcons</th>\n",
       "      <th>GTconswithoutIll250.GT</th>\n",
       "      <th>GTconswithoutIll300x.GT</th>\n",
       "      <th>GTconswithoutIllMP.GT</th>\n",
       "      <th>GTconswithoutTenX.GT</th>\n",
       "      <th>GTconswithoutpacbio.GT</th>\n",
       "      <th>GTsupp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>HG002</td>\n",
       "      <td>72766323</td>\n",
       "      <td>72811839</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>-45516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>977.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom  id sample     start       end      type    SVtype   Size  Ill250.GT  \\\n",
       "0     1  23  HG002  72766323  72811839  Deletion  Deletion -45516        1.0   \n",
       "\n",
       "   Ill250.alt_alnScore_mean   ...    tandemrep_pct  Label  GTconflict  GTcons  \\\n",
       "0                     977.7   ...         0.059979      1          -1       1   \n",
       "\n",
       "   GTconswithoutIll250.GT  GTconswithoutIll300x.GT  GTconswithoutIllMP.GT  \\\n",
       "0                       1                        1                      1   \n",
       "\n",
       "   GTconswithoutTenX.GT  GTconswithoutpacbio.GT  GTsupp  \n",
       "0                     1                       1       3  \n",
       "\n",
       "[1 rows x 193 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Training Data\n",
    "# SVanalyzer generated training data\n",
    "df_train = pd.read_csv('/Volumes/lesleydata/SVanalyzer_ML/Oct272017_ML_w_AllTech/data/train_test_data/train_data_min1.csv')\n",
    "df_train_2 = pd.read_csv('/Volumes/lesleydata/SVanalyzer_ML/Oct272017_ML_w_AllTech/data/train_test_data/train_data_min1.csv')\n",
    "df_train.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame()\n",
    "train_set = df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "train_set['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "train_set['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heterozygous_Variant    623\n",
       "Homozygous_Reference    971\n",
       "Homozygous_Variant      200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_set['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTE: Imbalanced classes in original training dataset. The following loads dataset with equal examples of each class **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Training Data\n",
    "# # SVanalyzer generated training data\n",
    "# df_train = pd.read_csv('/Volumes/lesleydata/SVanalyzer_ML/Oct272017_ML_w_AllTech/data/train_test_data/train_data_balanced.csv')\n",
    "# df_train_2 = pd.read_csv('/Volumes/lesleydata/SVanalyzer_ML/Oct272017_ML_w_AllTech/data/train_test_data/train_data_balanced.csv')\n",
    "# df_train.rename(columns={'size': 'Size'}, inplace=True)\n",
    "# df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame()\n",
    "train_set = df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "train_set['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "train_set['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heterozygous_Variant    623\n",
       "Homozygous_Reference    971\n",
       "Homozygous_Variant      200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_set['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model only on the rows that have an Exact Match or Homozygous Reference Label\n",
    "# This step removes any row that has in 'Inaccurate Call' label\n",
    "df_train = df_train[(df_train['Label'] == 1) | (df_train['Label'] == 0)]\n",
    "df_train_2 = df_train_2[(df_train_2['Label'] == 1) | (df_train_2['Label'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    969\n",
       "1    825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are only Exact Match [1] and Homozygous Reference Labels [0]\n",
    "pd.value_counts(df_train['Label'].values, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hom_ref'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>id</th>\n",
       "      <th>Size</th>\n",
       "      <th>sample</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>SVtype</th>\n",
       "      <th>Ill250.GT</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "      <th>GTconflict</th>\n",
       "      <th>GTcons</th>\n",
       "      <th>GTconswithoutIll250.GT</th>\n",
       "      <th>GTconswithoutIll300x.GT</th>\n",
       "      <th>GTconswithoutIllMP.GT</th>\n",
       "      <th>GTconswithoutTenX.GT</th>\n",
       "      <th>GTconswithoutpacbio.GT</th>\n",
       "      <th>GTsupp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>859</td>\n",
       "      <td>-115</td>\n",
       "      <td>HG002</td>\n",
       "      <td>37568322</td>\n",
       "      <td>37568587</td>\n",
       "      <td>Insertion</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.818868</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom   id  Size sample     start       end       type    SVtype  Ill250.GT  \\\n",
       "0     1  859  -115  HG002  37568322  37568587  Insertion  Deletion        0.0   \n",
       "\n",
       "   Ill250.alt_alnScore_mean   ...    tandemrep_cnt  tandemrep_pct  GTconflict  \\\n",
       "0                       0.0   ...                3       0.818868          -1   \n",
       "\n",
       "   GTcons  GTconswithoutIll250.GT  GTconswithoutIll300x.GT  \\\n",
       "0       0                       0                        0   \n",
       "\n",
       "   GTconswithoutIllMP.GT  GTconswithoutTenX.GT  GTconswithoutpacbio.GT  GTsupp  \n",
       "0                      0                     0                       0       4  \n",
       "\n",
       "[1 rows x 206 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Test Data\n",
    "# SVanalyzer generated training data\n",
    "df_test = pd.read_csv('/Volumes/lesleydata/SVanalyzer_ML/Oct272017_ML_w_AllTech/data/train_test_data/test_data_min1.csv')\n",
    "df_test_2 = pd.read_csv('/Volumes/lesleydata/SVanalyzer_ML/Oct272017_ML_w_AllTech/data/train_test_data/test_data_min1.csv')\n",
    "df_test.rename(columns={'size': 'Size'}, inplace=True)\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Label'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header names in lists and find names that are NOT contained in BOTH lists\n",
    "c = list(df_train.columns.values)\n",
    "d = list(df_test.columns.values)\n",
    "set(c) - set(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_train.drop(['Label'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconswithoutIll300x.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconswithoutIll250.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconswithoutIllMP.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconswithoutTenX.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconswithoutpacbio.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_train.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_train.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_train.drop(['sample'], axis=1, inplace = True)\n",
    "df_train.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_train.drop(['type'], axis=1, inplace = True)\n",
    "df_train.drop(['id'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>Size</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "      <th>GTcons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72766323</td>\n",
       "      <td>72811839</td>\n",
       "      <td>-45516</td>\n",
       "      <td>977.7</td>\n",
       "      <td>17.343875</td>\n",
       "      <td>20.0</td>\n",
       "      <td>451.85</td>\n",
       "      <td>87.001882</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>110</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom     start       end   Size  Ill250.alt_alnScore_mean  \\\n",
       "0     1  72766323  72811839 -45516                     977.7   \n",
       "\n",
       "   Ill250.alt_alnScore_std  Ill250.alt_count  Ill250.alt_insertSize_mean  \\\n",
       "0                17.343875              20.0                      451.85   \n",
       "\n",
       "   Ill250.alt_insertSize_std  Ill250.alt_reason_alignmentScore   ...    \\\n",
       "0                  87.001882                              17.0   ...     \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                         NaN                        NaN   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                               NaN         0         0           4   \n",
       "\n",
       "   segdup_pct  tandemrep_cnt  tandemrep_pct  GTcons  \n",
       "0    0.076523            110       0.059979       1  \n",
       "\n",
       "[1 rows x 176 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['chrom'].replace('X', 23, inplace=True)\n",
    "df_train['chrom'].replace('Y', 24, inplace=True)\n",
    "df_test['chrom'].replace('X', 23, inplace=True)\n",
    "df_test['chrom'].replace('Y', 24, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GTconflict',\n",
       " 'GTconswithoutIll250.GT',\n",
       " 'GTconswithoutIll300x.GT',\n",
       " 'GTconswithoutIllMP.GT',\n",
       " 'GTconswithoutTenX.GT',\n",
       " 'GTconswithoutpacbio.GT',\n",
       " 'GTsupp',\n",
       " 'Ill250.GT',\n",
       " 'Ill250.amb_reason_insertSizeScore_insertSizeScore',\n",
       " 'Ill250.amb_reason_insertSizeScore_orientation',\n",
       " 'Ill300x.GT',\n",
       " 'Ill300x.amb_reason_alignmentScore_insertSizeScore',\n",
       " 'Ill300x.amb_reason_insertSizeScore_orientation',\n",
       " 'Ill300x.amb_reason_orientation_insertSizeScore',\n",
       " 'IllMP.GT',\n",
       " 'IllMP.amb_reason_orientation_insertSizeScore',\n",
       " 'SVtype',\n",
       " 'TenX.GT',\n",
       " 'TenX.HP1_amb_reason_insertSizeScore_insertSizeScore',\n",
       " 'TenX.HP1_amb_reason_insertSizeScore_orientation',\n",
       " 'TenX.HP1_amb_reason_orientation_insertSizeScore',\n",
       " 'TenX.HP1_ref_reason_insertSizeScore',\n",
       " 'TenX.HP2_amb_reason_insertSizeScore_insertSizeScore',\n",
       " 'TenX.HP2_amb_reason_insertSizeScore_orientation',\n",
       " 'TenX.HP2_amb_reason_orientation_insertSizeScore',\n",
       " 'TenX.HP2_ref_reason_insertSizeScore',\n",
       " 'id',\n",
       " 'pacbio.GT',\n",
       " 'sample',\n",
       " 'type'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header names in lists and find names that are NOT contained in BOTH lists\n",
    "c = list(df_train.columns.values)\n",
    "d = list(df_test.columns.values)\n",
    "set(d) - set(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop columns that are not shared by both dataframes\n",
    "df_test.drop(['Ill300x.amb_reason_alignmentScore_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill300x.amb_reason_insertSizeScore_orientation'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill300x.amb_reason_orientation_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill250.amb_reason_insertSizeScore_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill250.amb_reason_insertSizeScore_orientation'], axis=1, inplace = True)\n",
    "df_test.drop(['IllMP.amb_reason_orientation_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP1_amb_reason_insertSizeScore_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP1_amb_reason_insertSizeScore_orientation'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP1_amb_reason_orientation_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP1_ref_reason_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP2_amb_reason_insertSizeScore_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP2_amb_reason_insertSizeScore_orientation'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP2_amb_reason_orientation_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.HP2_ref_reason_insertSizeScore'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconswithoutIll300x.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconswithoutIll250.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconswithoutIllMP.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconswithoutTenX.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconswithoutpacbio.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill300x.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['Ill250.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['IllMP.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['TenX.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['pacbio.GT'], axis=1, inplace = True)\n",
    "df_test.drop(['GTcons'], axis=1, inplace = True)\n",
    "df_test.drop(['GTconflict'], axis=1, inplace = True)\n",
    "df_test.drop(['GTsupp'], axis=1, inplace = True)\n",
    "df_test.drop(['sample'], axis=1, inplace = True)\n",
    "df_test.drop(['SVtype'], axis=1, inplace = True)\n",
    "df_test.drop(['type'], axis=1, inplace = True)\n",
    "df_test.drop(['id'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Impute missing values using KNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 176)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training data in a new variable which will be converted to a matrix\n",
    "X = df_train\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1794 with 22 missing, elapsed time: 2.774\n",
      "Imputing row 101/1794 with 1 missing, elapsed time: 2.822\n",
      "Imputing row 201/1794 with 1 missing, elapsed time: 2.826\n",
      "Imputing row 301/1794 with 1 missing, elapsed time: 2.832\n",
      "Imputing row 401/1794 with 1 missing, elapsed time: 2.836\n",
      "Imputing row 501/1794 with 1 missing, elapsed time: 2.845\n",
      "Imputing row 601/1794 with 1 missing, elapsed time: 2.849\n",
      "Imputing row 701/1794 with 1 missing, elapsed time: 2.856\n",
      "Imputing row 801/1794 with 1 missing, elapsed time: 2.863\n",
      "Imputing row 901/1794 with 0 missing, elapsed time: 2.891\n",
      "Imputing row 1001/1794 with 0 missing, elapsed time: 2.895\n",
      "Imputing row 1101/1794 with 0 missing, elapsed time: 2.900\n",
      "Imputing row 1201/1794 with 0 missing, elapsed time: 2.907\n",
      "Imputing row 1301/1794 with 0 missing, elapsed time: 2.910\n",
      "Imputing row 1401/1794 with 0 missing, elapsed time: 2.923\n",
      "Imputing row 1501/1794 with 0 missing, elapsed time: 2.928\n",
      "Imputing row 1601/1794 with 0 missing, elapsed time: 2.933\n",
      "Imputing row 1701/1794 with 0 missing, elapsed time: 2.935\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "X=X.as_matrix()\n",
    "\n",
    "#Imput missing values from three closest observations\n",
    "X_imputed=KNN(k=3).complete(X)\n",
    "X=pd.DataFrame(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>Size</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "      <th>GTcons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>72766323.0</td>\n",
       "      <td>72811839.0</td>\n",
       "      <td>-45516.0</td>\n",
       "      <td>977.700000</td>\n",
       "      <td>17.343875</td>\n",
       "      <td>20.0</td>\n",
       "      <td>451.850000</td>\n",
       "      <td>87.001882</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11040.571047</td>\n",
       "      <td>4079.336822</td>\n",
       "      <td>58.165391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>96139975.0</td>\n",
       "      <td>96142391.0</td>\n",
       "      <td>-2416.0</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>4.992302</td>\n",
       "      <td>26.0</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>98.968526</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10075.076920</td>\n",
       "      <td>4504.705061</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.014487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>109690878.0</td>\n",
       "      <td>109690918.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>956.666667</td>\n",
       "      <td>34.439964</td>\n",
       "      <td>18.0</td>\n",
       "      <td>408.277778</td>\n",
       "      <td>67.678000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12582.470590</td>\n",
       "      <td>3520.607336</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom        start          end     Size  Ill250.alt_alnScore_mean  \\\n",
       "0    1.0   72766323.0   72811839.0 -45516.0                977.700000   \n",
       "1    1.0   96139975.0   96142391.0  -2416.0                988.000000   \n",
       "2    1.0  109690878.0  109690918.0    -39.0                956.666667   \n",
       "\n",
       "   Ill250.alt_alnScore_std  Ill250.alt_count  Ill250.alt_insertSize_mean  \\\n",
       "0                17.343875              20.0                  451.850000   \n",
       "1                 4.992302              26.0                  449.000000   \n",
       "2                34.439964              18.0                  408.277778   \n",
       "\n",
       "   Ill250.alt_insertSize_std  Ill250.alt_reason_alignmentScore   ...    \\\n",
       "0                  87.001882                              17.0   ...     \n",
       "1                  98.968526                              23.0   ...     \n",
       "2                  67.678000                              18.0   ...     \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                11040.571047                4079.336822   \n",
       "1                10075.076920                4504.705061   \n",
       "2                12582.470590                3520.607336   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                         58.165391       0.0       0.0         4.0   \n",
       "1                         26.000000       0.0       0.0         0.0   \n",
       "2                         17.000000       0.0       0.0         0.0   \n",
       "\n",
       "   segdup_pct  tandemrep_cnt  tandemrep_pct  GTcons  \n",
       "0    0.076523          110.0       0.059979     1.0  \n",
       "1    0.000000            2.0       0.014487     1.0  \n",
       "2    0.000000            1.0       0.400000     1.0  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header values in a list, will be used later to re-label the matrix post KNN imputation\n",
    "dftrain_header = list(df_train.columns.values)\n",
    "X.columns = dftrain_header\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Labels in a new 'Y' DataFrame\n",
    "Y = pd.DataFrame()\n",
    "Y = X['GTcons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X4 = X.reindex_axis(sorted(X.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4.to_csv('post_imp_compare.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# Train on 70% of the data and test on 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=4, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=100, random_state=4, class_weight = \"balanced\") \n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_post = pd.concat([X_test, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test['predicted_label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/pandas/core/frame.py:2834: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test.rename(columns={'1': 'Homozygous_Reference'}, inplace=True)\n",
    "X_test.rename(columns={'2': 'Heterozygous_Variant'}, inplace=True)\n",
    "X_test.rename(columns={'3': 'Homozygous_Variant'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[296   1   0]\n",
      " [  0 185   0]\n",
      " [  0   1  56]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ytest = X_test['GTcons']\n",
    "predict = X_test['predicted_label']\n",
    "print(confusion_matrix(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
