{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Machine Learning Training Data : size stratification\n",
    "* Data originally pooled from all technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import io\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import plotly.plotly as py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "from bokeh.charts import TimeSeries\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.charts import Scatter, Histogram, output_file, show\n",
    "from bokeh.plotting import figure, show, output_file, ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "import bokeh.palettes as palettes\n",
    "from bokeh.models import HoverTool, BoxSelectTool, Legend\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Training Data\n",
    "df_20to49 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_20to49_train_.csv')\n",
    "df_50to99 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_50to99_train_.csv')\n",
    "df_100to299 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_100to299_train_.csv')\n",
    "df_300to399 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_300to399_train_.csv')\n",
    "df_400to499 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_400to499_train_.csv')\n",
    "df_500to999 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_500to999_train_.csv')\n",
    "df_1000to5999 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_1000to5999_train_.csv')\n",
    "df_6000 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_6000_train_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy Dataframes for later parsing tasks\n",
    "df_20to49_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_20to49_train.csv')\n",
    "df_50to99_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_50to99_train.csv')\n",
    "df_100to299_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_100to299_train.csv')\n",
    "df_300to399_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_300to399_train.csv')\n",
    "df_400to499_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_400to499_train.csv')\n",
    "df_500to999_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_500to999_train.csv')\n",
    "df_1000to5999_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_1000to5999_train.csv')\n",
    "df_6000_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/train/df_6000_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_20to49['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_20to49['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_50to99['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_50to99['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_50to99['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_100to299['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_100to299['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_100to299['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_300to399['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_300to399['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_300to399['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_400to499['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_400to499['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_400to499['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_500to999['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_500to999['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_500to999['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_1000to5999['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_1000to5999['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_1000to5999['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_6000['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_6000['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_6000['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imbalance'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hom_ref'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Test Data\n",
    "df_20to49_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_20to49_test_.csv')\n",
    "df_50to99_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_50to99_test_.csv')\n",
    "df_100to299_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_100to299_test_.csv')\n",
    "df_300to399_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_300to399_test_.csv')\n",
    "df_400to499_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_400to499_test_.csv')\n",
    "df_500to999_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_500to999_test_.csv')\n",
    "df_1000to5999_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_1000to5999_test_.csv')\n",
    "df_6000_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_6000_test_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Test Data\n",
    "df_20to49_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_20to49_test.csv')\n",
    "df_50to99_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_50to99_test.csv')\n",
    "df_100to299_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_100to299_test.csv')\n",
    "df_300to399_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_300to399_test.csv')\n",
    "df_400to499_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_400to499_test.csv')\n",
    "df_500to999_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_500to999_test.csv')\n",
    "df_1000to5999_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_1000to5999_test.csv')\n",
    "df_6000_test_ = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/test/df_6000_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_20to49_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_20to49_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_50to99_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_50to99_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_50to99_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_100to299_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_100to299_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_100to299_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_300to399_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_300to399_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_300to399_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_400to499_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_400to499_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_400to499_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_500to999_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_500to999_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_500to999_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_1000to5999_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_1000to5999_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_1000to5999_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_6000_test['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_6000_test['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_6000_test['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_20to49_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_20to49_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_50to99_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_50to99_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_50to99_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_100to299_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_100to299_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_100to299_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_300to399_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_300to399_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_300to399_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_400to499_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_400to499_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_400to499_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_500to999_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_500to999_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_500to999_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_1000to5999_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_1000to5999_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_1000to5999_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)\n",
    "\n",
    "df_6000_test_['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "df_6000_test_['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "df_6000_test_['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Store header names in lists and find names that are NOT contained in BOTH lists\n",
    "# c = list(df_train.columns.values)\n",
    "# d = list(df_test.columns.values)\n",
    "# set(d) - set(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "EDA\n",
    "\n",
    "Size distribution of sampled data set [all size datasets pooled]\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/train/random_sample_SizeBins_szwt_train.csv')\n",
    "df_test = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/test/random_sample_SizeBins_szwt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['Size'].abs()\n",
    "df_test['Size'].abs()\n",
    "df_test = df_test[df_test['Size'] >= 20]\n",
    "\n",
    "df_train['log_size'] = np.log10(df_train.Size)\n",
    "df_test['log_size'] = np.log10(df_test.Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style(\"white\")\n",
    "# p = df_train['log_size'].hist(alpha = 0.5, bins = 30, edgecolor='black', label='hom_var')\n",
    "# p.grid(False)\n",
    "# p.set_xlabel('Size[log10]')\n",
    "# p.set_ylabel('Frequency')\n",
    "# p.set_title('Training Set')\n",
    "# # plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/SizeDist_training.png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style(\"white\")\n",
    "# p = df_test['log_size'].hist(alpha = 0.5, bins = 30, edgecolor='black', label='hom_var')\n",
    "# p.grid(False)\n",
    "# p.set_xlabel('Size[log10]')\n",
    "# p.set_ylabel('Frequency')\n",
    "# p.set_title('Test Set')\n",
    "# plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/SizeDist_test.png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**20-49bp**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Impute missing values using KNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>976.871795</td>\n",
       "      <td>12.113098</td>\n",
       "      <td>39.0</td>\n",
       "      <td>431.384615</td>\n",
       "      <td>91.092406</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>890.273292</td>\n",
       "      <td>...</td>\n",
       "      <td>8754.50</td>\n",
       "      <td>3356.194618</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65359519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>907.097143</td>\n",
       "      <td>...</td>\n",
       "      <td>10767.32</td>\n",
       "      <td>3791.304854</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44564287</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>980.865672</td>\n",
       "      <td>12.845692</td>\n",
       "      <td>67.0</td>\n",
       "      <td>430.701492</td>\n",
       "      <td>88.234426</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>883.863905</td>\n",
       "      <td>...</td>\n",
       "      <td>18545.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96806440</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0       1                976.871795                12.113098   \n",
       "1       0                  0.000000                 0.000000   \n",
       "2       1                980.865672                12.845692   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              39.0                  431.384615                  91.092406   \n",
       "1               0.0                    0.000000                   0.000000   \n",
       "2              67.0                  430.701492                  88.234426   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                              39.0                                0.0   \n",
       "1                               0.0                                0.0   \n",
       "2                              67.0                                0.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean      ...        \\\n",
       "0                            0.0                890.273292      ...         \n",
       "1                            0.0                907.097143      ...         \n",
       "2                            0.0                883.863905      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                     8754.50                3356.194618   \n",
       "1                    10767.32                3791.304854   \n",
       "2                    18545.00                   0.000000   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              30.0         0         0           0   \n",
       "1                              50.0         0         0           0   \n",
       "2                               1.0         0         0           1   \n",
       "\n",
       "   segdup_pct     start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  65359519              0       0.000000  \n",
       "1         0.0  44564287              1       1.000000  \n",
       "2         1.0  96806440              1       0.586207  \n",
       "\n",
       "[3 rows x 177 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store training data in a new variable which will be converted to a matrix\n",
    "X = df_20to49\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1581 with 1 missing, elapsed time: 2.159\n",
      "Imputing row 101/1581 with 1 missing, elapsed time: 2.214\n",
      "Imputing row 201/1581 with 2 missing, elapsed time: 2.226\n",
      "Imputing row 301/1581 with 2 missing, elapsed time: 2.238\n",
      "Imputing row 401/1581 with 2 missing, elapsed time: 2.249\n",
      "Imputing row 501/1581 with 2 missing, elapsed time: 2.263\n",
      "Imputing row 601/1581 with 1 missing, elapsed time: 2.272\n",
      "Imputing row 701/1581 with 2 missing, elapsed time: 2.284\n",
      "Imputing row 801/1581 with 1 missing, elapsed time: 2.295\n",
      "Imputing row 901/1581 with 58 missing, elapsed time: 2.305\n",
      "Imputing row 1001/1581 with 2 missing, elapsed time: 2.313\n",
      "Imputing row 1101/1581 with 1 missing, elapsed time: 2.329\n",
      "Imputing row 1201/1581 with 2 missing, elapsed time: 2.342\n",
      "Imputing row 1301/1581 with 2 missing, elapsed time: 2.355\n",
      "Imputing row 1401/1581 with 1 missing, elapsed time: 2.369\n",
      "Imputing row 1501/1581 with 2 missing, elapsed time: 2.388\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "X=X.as_matrix()\n",
    "\n",
    "#Imput missing values from three closest observations\n",
    "X_imputed=KNN(k=3).complete(X)\n",
    "X=pd.DataFrame(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTcons</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>976.871795</td>\n",
       "      <td>12.113098</td>\n",
       "      <td>39.0</td>\n",
       "      <td>431.384615</td>\n",
       "      <td>91.092406</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>890.273292</td>\n",
       "      <td>...</td>\n",
       "      <td>8754.50</td>\n",
       "      <td>3356.194618</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65359519.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>907.097143</td>\n",
       "      <td>...</td>\n",
       "      <td>10767.32</td>\n",
       "      <td>3791.304854</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44564287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>980.865672</td>\n",
       "      <td>12.845692</td>\n",
       "      <td>67.0</td>\n",
       "      <td>430.701492</td>\n",
       "      <td>88.234426</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>883.863905</td>\n",
       "      <td>...</td>\n",
       "      <td>18545.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96806440.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GTcons  Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  \\\n",
       "0     1.0                976.871795                12.113098   \n",
       "1     0.0                  0.000000                 0.000000   \n",
       "2     1.0                980.865672                12.845692   \n",
       "\n",
       "   Ill250.alt_count  Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0              39.0                  431.384615                  91.092406   \n",
       "1               0.0                    0.000000                   0.000000   \n",
       "2              67.0                  430.701492                  88.234426   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                              39.0                                0.0   \n",
       "1                               0.0                                0.0   \n",
       "2                              67.0                                0.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean      ...        \\\n",
       "0                            0.0                890.273292      ...         \n",
       "1                            0.0                907.097143      ...         \n",
       "2                            0.0                883.863905      ...         \n",
       "\n",
       "   pacbio.ref_insertSize_mean  pacbio.ref_insertSize_std  \\\n",
       "0                     8754.50                3356.194618   \n",
       "1                    10767.32                3791.304854   \n",
       "2                    18545.00                   0.000000   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  refN_cnt  refN_pct  segdup_cnt  \\\n",
       "0                              30.0       0.0       0.0         0.0   \n",
       "1                              50.0       0.0       0.0         0.0   \n",
       "2                               1.0       0.0       0.0         1.0   \n",
       "\n",
       "   segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0.0  65359519.0            0.0       0.000000  \n",
       "1         0.0  44564287.0            1.0       1.000000  \n",
       "2         1.0  96806440.0            1.0       0.586207  \n",
       "\n",
       "[3 rows x 177 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store header values in a list, will be used later to re-label the matrix post KNN imputation\n",
    "df_20to49_header = list(df_20to49.columns.values)\n",
    "X.columns = df_20to49_header\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Labels in a new 'Y' DataFrame\n",
    "Y = pd.DataFrame()\n",
    "Y = X['GTcons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    855\n",
       "0.0    453\n",
       "2.0    273\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of labels\n",
    "pd.value_counts(Y.values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove labels from feature set\n",
    "X.drop(['GTcons'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X4 = X.reindex_axis(sorted(X.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Machine Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine_learning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Random Forest Classifier **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi_run'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Determine Number of trees: Out of Bag Error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "# Train on 70% of the data and test on 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(oob_score=True, class_weight='balanced') \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE :** \n",
    "\n",
    "Determined OOB score based on 70% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n",
      "/Users/lmc2/anaconda/envs/NIHFAES/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning:\n",
      "\n",
      "Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 50\n",
    "trees = []\n",
    "oob = []\n",
    "for i in range(1, n_estimators):\n",
    "    model.set_params(n_estimators=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    trees += [i]\n",
    "    oob += [model.oob_score_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_oob = pd.DataFrame()\n",
    "# df_oob['trees'] = trees\n",
    "# df_oob['oob'] = oob\n",
    "\n",
    "# ax = plt.plot(trees, oob)\n",
    "# sns.set_style(\"white\")\n",
    "# plt.xlabel(\"Number of Trees [n_estimators]\")\n",
    "# plt.ylabel(\"OOB error rate\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/20-45bp_OOB.png', bbox_inches='tight')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train Model Using Optimal Tuning Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "            oob_score=False, random_state=4, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=15, random_state=4, class_weight=\"balanced\") \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Another Resource](https://stackoverflow.com/questions/37877542/how-to-label-the-feature-importance-with-forests-of-trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='100_trees'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # %matplotlib inline\n",
    "# feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "# feature_importances.sort()\n",
    "# # # plt.figure(figsize=(37, 37))\n",
    "# # plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/df_20to49_featureImportance.png', bbox_inches='tight')\n",
    "# # feature_importances.plot(kind=\"barh\", figsize=(8,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/feature_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = X4[['pacbio.alt_reason_alignmentScore','Ill300x.alt_count','pacbio.ref_insertSize_std','pacbio.alt_alnScore_std','pacbio.ref_reason_alignmentScore','Ill250.ref_count','Ill250.alt_alnScore_std','Ill250.ref_reason_alignmentScore','Ill300x.ref_reason_alignmentScore','IllMP.ref_reason_alignmentScore','pacbio.alt_insertSize_std','pacbio.ref_alnScore_mean','Ill300x.ref_count','pacbio.ref_count','Ill300x.alt_insertSize_std','TenX.HP1_alt_alnScore_std','IllMP.ref_insertSize_std','IllMP.ref_count','TenX.HP2_alt_count','Ill250.alt_reason_alignmentScore','Ill250.ref_alnScore_std','Ill250.alt_insertSize_mean','TenX.HP1_alt_insertSize_std','pacbio.alt_count','pacbio.ref_insertSize_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(X_.corr(), annot=True, fmt=\".2f\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.yticks(rotation='horizontal')\n",
    "# plt.figure(figsize=(18, 18))\n",
    "plt.show()\n",
    "# plt.savefig('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/figures/df_20to49_heatmap.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    585\n",
       "0.0    318\n",
       "2.0    203\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: Training Set - Show number of Hom Ref, Hom Var, Het Var datapoints the model was trained on\n",
    "ytrain = pd.DataFrame()\n",
    "ytrain['ytrain'] = y_train\n",
    "pd.value_counts(ytrain['ytrain'].values, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='traintest_precision'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the training subset: 0.994\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the training subset: {:.3f}'.format(precision_score(y_test, pred, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training subset: 0.994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score of the training subset: {:.3f}'.format(accuracy_score(y_test, pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>919.444444</td>\n",
       "      <td>32.741788</td>\n",
       "      <td>9.0</td>\n",
       "      <td>459.444444</td>\n",
       "      <td>55.869115</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>838.472362</td>\n",
       "      <td>169.929214</td>\n",
       "      <td>...</td>\n",
       "      <td>9513.550000</td>\n",
       "      <td>3068.909260</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2271928.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>853.346369</td>\n",
       "      <td>155.952624</td>\n",
       "      <td>...</td>\n",
       "      <td>9678.200000</td>\n",
       "      <td>4744.647503</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37934677.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>874.669603</td>\n",
       "      <td>147.021863</td>\n",
       "      <td>...</td>\n",
       "      <td>8565.116279</td>\n",
       "      <td>3239.740301</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9486223.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>987.953125</td>\n",
       "      <td>11.373530</td>\n",
       "      <td>64.0</td>\n",
       "      <td>435.953125</td>\n",
       "      <td>84.495826</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>890.350711</td>\n",
       "      <td>156.522973</td>\n",
       "      <td>...</td>\n",
       "      <td>5104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197451502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>976.459016</td>\n",
       "      <td>11.563898</td>\n",
       "      <td>61.0</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>82.541991</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>890.353293</td>\n",
       "      <td>159.817226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50523485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "1229                919.444444                32.741788               9.0   \n",
       "932                   0.000000                 0.000000               0.0   \n",
       "302                   0.000000                 0.000000               0.0   \n",
       "1309                987.953125                11.373530              64.0   \n",
       "532                 976.459016                11.563898              61.0   \n",
       "\n",
       "      Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "1229                  459.444444                  55.869115   \n",
       "932                     0.000000                   0.000000   \n",
       "302                     0.000000                   0.000000   \n",
       "1309                  435.953125                  84.495826   \n",
       "532                   440.000000                  82.541991   \n",
       "\n",
       "      Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "1229                               9.0                                0.0   \n",
       "932                                0.0                                0.0   \n",
       "302                                0.0                                0.0   \n",
       "1309                              64.0                                0.0   \n",
       "532                               61.0                                0.0   \n",
       "\n",
       "      Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean  \\\n",
       "1229                            0.0                838.472362   \n",
       "932                             0.0                853.346369   \n",
       "302                             0.0                874.669603   \n",
       "1309                            0.0                890.350711   \n",
       "532                             0.0                890.353293   \n",
       "\n",
       "      Ill250.amb_alnScore_std      ...        pacbio.ref_insertSize_mean  \\\n",
       "1229               169.929214      ...                       9513.550000   \n",
       "932                155.952624      ...                       9678.200000   \n",
       "302                147.021863      ...                       8565.116279   \n",
       "1309               156.522973      ...                       5104.000000   \n",
       "532                159.817226      ...                          0.000000   \n",
       "\n",
       "      pacbio.ref_insertSize_std  pacbio.ref_reason_alignmentScore  refN_cnt  \\\n",
       "1229                3068.909260                              20.0       0.0   \n",
       "932                 4744.647503                              35.0       0.0   \n",
       "302                 3239.740301                              43.0       0.0   \n",
       "1309                   0.000000                               1.0       0.0   \n",
       "532                    0.000000                               0.0       0.0   \n",
       "\n",
       "      refN_pct  segdup_cnt  segdup_pct        start  tandemrep_cnt  \\\n",
       "1229       0.0         0.0         0.0    2271928.0            1.0   \n",
       "932        0.0         0.0         0.0   37934677.0            1.0   \n",
       "302        0.0         0.0         0.0    9486223.0            1.0   \n",
       "1309       0.0         0.0         0.0  197451502.0            0.0   \n",
       "532        0.0         0.0         0.0   50523485.0            0.0   \n",
       "\n",
       "      tandemrep_pct  \n",
       "1229            1.0  \n",
       "932             1.0  \n",
       "302             1.0  \n",
       "1309            0.0  \n",
       "532             0.0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add original labels and predicted labels back to the original dataframe\n",
    "df_Xtest = pd.DataFrame(X_test)\n",
    "df_Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['predicted_label'] = pred\n",
    "df_Xtest['GTcons'] = df_20to49['GTcons']\n",
    "df_Xtest['chrom'] = df_20to49['chrom']\n",
    "df_Xtest['start'] = df_20to49['start']\n",
    "df_Xtest['end'] = df_20to49['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest['GTcons'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['GTcons'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['GTcons'].replace(2.0, 'Homozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "df_Xtest['predicted_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heterozygous_Variant    270\n",
       "Homozygous_Reference    135\n",
       "Homozygous_Variant       70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_Xtest['GTcons'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heterozygous_Variant    273\n",
       "Homozygous_Reference    133\n",
       "Homozygous_Variant       69\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_Xtest['predicted_label'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[270   0   0]\n",
      " [  2 133   0]\n",
      " [  1   0  69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ytest = df_Xtest['GTcons']\n",
    "predict = df_Xtest['predicted_label']\n",
    "print(confusion_matrix(ytest, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>273</td>\n",
       "      <td>133</td>\n",
       "      <td>69</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   270                     0   \n",
       "Homozygous_Reference                     2                   133   \n",
       "Homozygous_Variant                       1                     0   \n",
       "All                                    273                   133   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  270  \n",
       "Homozygous_Reference                   0  135  \n",
       "Homozygous_Variant                    69   70  \n",
       "All                                   69  475  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='traintest_confusion_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Pandas: save table to HTML\n",
    "# p = pd.crosstab(ytest, predict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "# p.to_html('cro.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       0.99      1.00      0.99       270\n",
      "Homozygous_Reference       1.00      0.99      0.99       135\n",
      "  Homozygous_Variant       1.00      0.99      0.99        70\n",
      "\n",
      "         avg / total       0.99      0.99      0.99       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Predict\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "   * In the [previous section](#machine_learning), a RF model was trained on svanalyzer data.\n",
    "\n",
    "       * The model was trained using [train/test split](#train_test) where 70% of the data was used to train the model and the model performance was determined by predicting labels for the remaining 30% of the data\n",
    " * Reminder: The labels for this training set and the following [prediction step](#prediction_step) are the consensus genotype (GTcons) labels generated from a preliminary R analysis based on reference and alternate read count:\n",
    "           * Homozygous Reference (0)\n",
    "           * Heterozygous Variant (1)\n",
    "           * Homozygous Variant (2)\n",
    "           \n",
    "   * The trained model is used in the following section to predict labels for 5000 randomly selected Deletions [these datapoints were randomly selected from [union_170509_refalt.sort.vcf](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_UnionSVs_05092017/)]\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_20to49_test.drop(['GTcons'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df_20to49_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1769 with 2 missing, elapsed time: 2.644\n",
      "Imputing row 101/1769 with 2 missing, elapsed time: 2.652\n",
      "Imputing row 201/1769 with 2 missing, elapsed time: 2.662\n",
      "Imputing row 301/1769 with 1 missing, elapsed time: 2.677\n",
      "Imputing row 401/1769 with 57 missing, elapsed time: 2.686\n",
      "Imputing row 501/1769 with 1 missing, elapsed time: 2.693\n",
      "Imputing row 601/1769 with 2 missing, elapsed time: 2.726\n",
      "Imputing row 701/1769 with 2 missing, elapsed time: 2.735\n",
      "Imputing row 801/1769 with 2 missing, elapsed time: 2.744\n",
      "Imputing row 901/1769 with 2 missing, elapsed time: 2.763\n",
      "Imputing row 1001/1769 with 2 missing, elapsed time: 2.774\n",
      "Imputing row 1101/1769 with 1 missing, elapsed time: 2.800\n",
      "Imputing row 1201/1769 with 1 missing, elapsed time: 2.805\n",
      "Imputing row 1301/1769 with 1 missing, elapsed time: 2.822\n",
      "Imputing row 1401/1769 with 1 missing, elapsed time: 2.828\n",
      "Imputing row 1501/1769 with 1 missing, elapsed time: 2.834\n",
      "Imputing row 1601/1769 with 2 missing, elapsed time: 2.859\n",
      "Imputing row 1701/1769 with 2 missing, elapsed time: 2.870\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>956.666667</td>\n",
       "      <td>34.439964</td>\n",
       "      <td>18.0</td>\n",
       "      <td>408.277778</td>\n",
       "      <td>67.678000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>865.890351</td>\n",
       "      <td>144.648004</td>\n",
       "      <td>...</td>\n",
       "      <td>12582.470590</td>\n",
       "      <td>3520.607336</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109690878.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>907.800000</td>\n",
       "      <td>32.058696</td>\n",
       "      <td>5.0</td>\n",
       "      <td>515.800000</td>\n",
       "      <td>111.528292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>824.633663</td>\n",
       "      <td>143.131195</td>\n",
       "      <td>...</td>\n",
       "      <td>11108.692310</td>\n",
       "      <td>2980.377554</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5928792.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>974.944444</td>\n",
       "      <td>23.945476</td>\n",
       "      <td>18.0</td>\n",
       "      <td>414.055556</td>\n",
       "      <td>82.909906</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.661458</td>\n",
       "      <td>131.117492</td>\n",
       "      <td>...</td>\n",
       "      <td>9705.333333</td>\n",
       "      <td>3314.150040</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22352395.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                956.666667                34.439964              18.0   \n",
       "1                907.800000                32.058696               5.0   \n",
       "2                974.944444                23.945476              18.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  408.277778                  67.678000   \n",
       "1                  515.800000                 111.528292   \n",
       "2                  414.055556                  82.909906   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                              18.0                                0.0   \n",
       "1                               5.0                                0.0   \n",
       "2                              18.0                                0.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean  \\\n",
       "0                            0.0                865.890351   \n",
       "1                            0.0                824.633663   \n",
       "2                            0.0                850.661458   \n",
       "\n",
       "   Ill250.amb_alnScore_std      ...        pacbio.ref_insertSize_mean  \\\n",
       "0               144.648004      ...                      12582.470590   \n",
       "1               143.131195      ...                      11108.692310   \n",
       "2               131.117492      ...                       9705.333333   \n",
       "\n",
       "   pacbio.ref_insertSize_std  pacbio.ref_reason_alignmentScore  refN_cnt  \\\n",
       "0                3520.607336                              17.0       0.0   \n",
       "1                2980.377554                              26.0       0.0   \n",
       "2                3314.150040                              15.0       0.0   \n",
       "\n",
       "   refN_pct  segdup_cnt  segdup_pct        start  tandemrep_cnt  tandemrep_pct  \n",
       "0       0.0         0.0         0.0  109690878.0            1.0       0.400000  \n",
       "1       0.0         0.0         0.0    5928792.0            1.0       0.518519  \n",
       "2       0.0         0.0         0.0   22352395.0            1.0       0.629630  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20to49_test_header = list(df_20to49_test.columns.values)\n",
    "X2.columns = df_20to49_test_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>956.666667</td>\n",
       "      <td>34.439964</td>\n",
       "      <td>18.0</td>\n",
       "      <td>408.277778</td>\n",
       "      <td>67.678000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>865.890351</td>\n",
       "      <td>144.648004</td>\n",
       "      <td>...</td>\n",
       "      <td>12582.470590</td>\n",
       "      <td>3520.607336</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109690878.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>907.800000</td>\n",
       "      <td>32.058696</td>\n",
       "      <td>5.0</td>\n",
       "      <td>515.800000</td>\n",
       "      <td>111.528292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>824.633663</td>\n",
       "      <td>143.131195</td>\n",
       "      <td>...</td>\n",
       "      <td>11108.692310</td>\n",
       "      <td>2980.377554</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5928792.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>974.944444</td>\n",
       "      <td>23.945476</td>\n",
       "      <td>18.0</td>\n",
       "      <td>414.055556</td>\n",
       "      <td>82.909906</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.661458</td>\n",
       "      <td>131.117492</td>\n",
       "      <td>...</td>\n",
       "      <td>9705.333333</td>\n",
       "      <td>3314.150040</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22352395.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                956.666667                34.439964              18.0   \n",
       "1                907.800000                32.058696               5.0   \n",
       "2                974.944444                23.945476              18.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                  408.277778                  67.678000   \n",
       "1                  515.800000                 111.528292   \n",
       "2                  414.055556                  82.909906   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                              18.0                                0.0   \n",
       "1                               5.0                                0.0   \n",
       "2                              18.0                                0.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean  \\\n",
       "0                            0.0                865.890351   \n",
       "1                            0.0                824.633663   \n",
       "2                            0.0                850.661458   \n",
       "\n",
       "   Ill250.amb_alnScore_std      ...        pacbio.ref_insertSize_mean  \\\n",
       "0               144.648004      ...                      12582.470590   \n",
       "1               143.131195      ...                      11108.692310   \n",
       "2               131.117492      ...                       9705.333333   \n",
       "\n",
       "   pacbio.ref_insertSize_std  pacbio.ref_reason_alignmentScore  refN_cnt  \\\n",
       "0                3520.607336                              17.0       0.0   \n",
       "1                2980.377554                              26.0       0.0   \n",
       "2                3314.150040                              15.0       0.0   \n",
       "\n",
       "   refN_pct  segdup_cnt  segdup_pct        start  tandemrep_cnt  tandemrep_pct  \n",
       "0       0.0         0.0         0.0  109690878.0            1.0       0.400000  \n",
       "1       0.0         0.0         0.0    5928792.0            1.0       0.518519  \n",
       "2       0.0         0.0         0.0   22352395.0            1.0       0.629630  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_20to49_test_['chrom']\n",
    "X5['GTcons'] = df_20to49_test_['GTcons']\n",
    "X5['start'] = df_20to49_test_['start']\n",
    "X5['end'] = df_20to49_test_['end']\n",
    "X5['Size'] = df_20to49_test_['Size']\n",
    "X5['GTsupp'] = df_20to49_test_['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homozygous_Reference_GTcons</th>\n",
       "      <th>Heterozygous_Variant_GTcons</th>\n",
       "      <th>Homozygous_Variant_GTcons</th>\n",
       "      <th>GTcons</th>\n",
       "      <th>GTsupp</th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>predicted_GTcons_label</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>956.666667</td>\n",
       "      <td>34.439964</td>\n",
       "      <td>18.0</td>\n",
       "      <td>408.277778</td>\n",
       "      <td>67.678000</td>\n",
       "      <td>...</td>\n",
       "      <td>3520.607336</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109690878</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>907.800000</td>\n",
       "      <td>32.058696</td>\n",
       "      <td>5.0</td>\n",
       "      <td>515.800000</td>\n",
       "      <td>111.528292</td>\n",
       "      <td>...</td>\n",
       "      <td>2980.377554</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5928792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>974.944444</td>\n",
       "      <td>23.945476</td>\n",
       "      <td>18.0</td>\n",
       "      <td>414.055556</td>\n",
       "      <td>82.909906</td>\n",
       "      <td>...</td>\n",
       "      <td>3314.150040</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22352395</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Homozygous_Reference_GTcons  Heterozygous_Variant_GTcons  \\\n",
       "0                     0.066667                     0.933333   \n",
       "1                     0.066667                     0.800000   \n",
       "2                     0.000000                     1.000000   \n",
       "\n",
       "   Homozygous_Variant_GTcons  GTcons  GTsupp  Ill250.alt_alnScore_mean  \\\n",
       "0                   0.000000       1       4                956.666667   \n",
       "1                   0.133333       1       2                907.800000   \n",
       "2                   0.000000       1       3                974.944444   \n",
       "\n",
       "   Ill250.alt_alnScore_std  Ill250.alt_count  Ill250.alt_insertSize_mean  \\\n",
       "0                34.439964              18.0                  408.277778   \n",
       "1                32.058696               5.0                  515.800000   \n",
       "2                23.945476              18.0                  414.055556   \n",
       "\n",
       "   Ill250.alt_insertSize_std      ...        pacbio.ref_insertSize_std  \\\n",
       "0                  67.678000      ...                      3520.607336   \n",
       "1                 111.528292      ...                      2980.377554   \n",
       "2                  82.909906      ...                      3314.150040   \n",
       "\n",
       "   pacbio.ref_reason_alignmentScore  predicted_GTcons_label  refN_cnt  \\\n",
       "0                              17.0                       1         0   \n",
       "1                              26.0                       1         0   \n",
       "2                              15.0                       1         0   \n",
       "\n",
       "   refN_pct  segdup_cnt  segdup_pct      start  tandemrep_cnt  tandemrep_pct  \n",
       "0         0           0         0.0  109690878              1       0.400000  \n",
       "1         0           0         0.0    5928792              1       0.518519  \n",
       "2         0           0         0.0   22352395              1       0.629630  \n",
       "\n",
       "[3 rows x 182 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X6['GTcons'].replace('Homozygous_Reference', 0, inplace=True)\n",
    "# X6['GTcons'].replace('Heterozygous_Variant', 1, inplace=True)\n",
    "# X6['GTcons'].replace('Homozygous_Variant', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X7['GTcons'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "  * The [random forest(RF) model](#train_test) was trained on svanalyzer data. The trained model was used to predict consensus GT labels for the 5000 deletions that were randomly selected from the union_refalt vcf. The following is a comparison of model predicted labels [Conesus GT] to consensus genotype generated by the R script for the 5000 randomly selected datapoints from union_refalt.vcf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[487   5   0]\n",
      " [  9 956   4]\n",
      " [  3   7 298]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.984\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the prediction subset: 0.975\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>956</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>5</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>968</td>\n",
       "      <td>499</td>\n",
       "      <td>302</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   956                     9   \n",
       "Homozygous_Reference                     5                   487   \n",
       "Homozygous_Variant                       7                     3   \n",
       "All                                    968                   499   \n",
       "\n",
       "Predicted             Homozygous_Variant   All  \n",
       "True                                            \n",
       "Heterozygous_Variant                   4   969  \n",
       "Homozygous_Reference                   0   492  \n",
       "Homozygous_Variant                   298   308  \n",
       "All                                  302  1769  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>798</td>\n",
       "      <td>450</td>\n",
       "      <td>187</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   798                     0   \n",
       "Homozygous_Reference                     0                   450   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                    798                   450   \n",
       "\n",
       "Predicted             Homozygous_Variant   All  \n",
       "True                                            \n",
       "Heterozygous_Variant                   0   798  \n",
       "Homozygous_Reference                   0   450  \n",
       "Homozygous_Variant                   187   187  \n",
       "All                                  187  1435  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       1.00      1.00      1.00       798\n",
      "Homozygous_Reference       1.00      1.00      1.00       450\n",
      "  Homozygous_Variant       1.00      1.00      1.00       187\n",
      "\n",
      "         avg / total       1.00      1.00      1.00      1435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Predict**\n",
    "\n",
    "\n",
    "How well does a model trained on small variants predict GT of large variants?\n",
    "Variants : 1000 - 5999 bp\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n",
    "   * In the [previous section](#machine_learning), a RF model was trained on svanalyzer data.\n",
    "\n",
    "       * The model was trained using [train/test split](#train_test) where 70% of the data was used to train the model and the model performance was determined by predicting labels for the remaining 30% of the data\n",
    " * Reminder: The labels for this training set and the following [prediction step](#prediction_step) are the consensus genotype (GTcons) labels generated from a preliminary R analysis based on reference and alternate read count:\n",
    "           * Homozygous Reference (0)\n",
    "           * Heterozygous Variant (1)\n",
    "           * Homozygous Variant (2)\n",
    "           \n",
    "   * The trained model is used in the following section to predict labels for 5000 randomly selected Deletions [these datapoints were randomly selected from [union_170509_refalt.sort.vcf](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_UnionSVs_05092017/)]\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load Data **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pool all datasets with large variants 1000 - 6000+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_1000to5999, df_1000to5999_test, df_6000, df_6000_test], axis=0)\n",
    "df = df.reset_index()\n",
    "df2 = df\n",
    "df_ = pd.concat([df_1000to5999_, df_1000to5999_test_, df_6000_, df_6000_test_], axis=0)\n",
    "df_ = df_.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['GTcons'],axis=1, inplace=True)\n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df_.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Impute missing values using KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/284 with 1 missing, elapsed time: 0.075\n",
      "Imputing row 101/284 with 1 missing, elapsed time: 0.090\n",
      "Imputing row 201/284 with 57 missing, elapsed time: 0.096\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe to matrix\n",
    "X2=X2.as_matrix()\n",
    "X2=pd.DataFrame(X2)\n",
    "\n",
    "# Imput missing values from three closest observations\n",
    "X2_imputed=KNN(k=3).complete(X2)\n",
    "X2=pd.DataFrame(X2_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>872.238636</td>\n",
       "      <td>151.265870</td>\n",
       "      <td>...</td>\n",
       "      <td>10683.11594</td>\n",
       "      <td>5291.525830</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66398770.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.097264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>972.727273</td>\n",
       "      <td>15.764407</td>\n",
       "      <td>44.0</td>\n",
       "      <td>446.931818</td>\n",
       "      <td>81.055368</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>861.743750</td>\n",
       "      <td>161.249545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14189915.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.037082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>977.161290</td>\n",
       "      <td>15.238103</td>\n",
       "      <td>31.0</td>\n",
       "      <td>422.161290</td>\n",
       "      <td>57.943853</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>886.130045</td>\n",
       "      <td>129.576288</td>\n",
       "      <td>...</td>\n",
       "      <td>10714.20833</td>\n",
       "      <td>3615.789459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20950622.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.076469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                  0.000000                 0.000000               0.0   \n",
       "1                972.727273                15.764407              44.0   \n",
       "2                977.161290                15.238103              31.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                    0.000000                   0.000000   \n",
       "1                  446.931818                  81.055368   \n",
       "2                  422.161290                  57.943853   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                               0.0                                0.0   \n",
       "1                              35.0                                9.0   \n",
       "2                              28.0                                3.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean  \\\n",
       "0                            0.0                872.238636   \n",
       "1                            0.0                861.743750   \n",
       "2                            0.0                886.130045   \n",
       "\n",
       "   Ill250.amb_alnScore_std      ...        pacbio.ref_insertSize_mean  \\\n",
       "0               151.265870      ...                       10683.11594   \n",
       "1               161.249545      ...                           0.00000   \n",
       "2               129.576288      ...                       10714.20833   \n",
       "\n",
       "   pacbio.ref_insertSize_std  pacbio.ref_reason_alignmentScore  refN_cnt  \\\n",
       "0                5291.525830                              69.0       0.0   \n",
       "1                   0.000000                               0.0       0.0   \n",
       "2                3615.789459                              24.0       0.0   \n",
       "\n",
       "   refN_pct  segdup_cnt  segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0       0.0         0.0         0.0  66398770.0            6.0       0.097264  \n",
       "1       0.0         0.0         0.0  14189915.0            3.0       0.037082  \n",
       "2       0.0         0.0         0.0  20950622.0           10.0       0.076469  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_header = list(df.columns.values)\n",
    "X2.columns = df_header\n",
    "X2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>872.238636</td>\n",
       "      <td>151.265870</td>\n",
       "      <td>...</td>\n",
       "      <td>10683.11594</td>\n",
       "      <td>5291.525830</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66398770.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.097264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>972.727273</td>\n",
       "      <td>15.764407</td>\n",
       "      <td>44.0</td>\n",
       "      <td>446.931818</td>\n",
       "      <td>81.055368</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>861.743750</td>\n",
       "      <td>161.249545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14189915.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.037082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>977.161290</td>\n",
       "      <td>15.238103</td>\n",
       "      <td>31.0</td>\n",
       "      <td>422.161290</td>\n",
       "      <td>57.943853</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>886.130045</td>\n",
       "      <td>129.576288</td>\n",
       "      <td>...</td>\n",
       "      <td>10714.20833</td>\n",
       "      <td>3615.789459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20950622.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.076469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ill250.alt_alnScore_mean  Ill250.alt_alnScore_std  Ill250.alt_count  \\\n",
       "0                  0.000000                 0.000000               0.0   \n",
       "1                972.727273                15.764407              44.0   \n",
       "2                977.161290                15.238103              31.0   \n",
       "\n",
       "   Ill250.alt_insertSize_mean  Ill250.alt_insertSize_std  \\\n",
       "0                    0.000000                   0.000000   \n",
       "1                  446.931818                  81.055368   \n",
       "2                  422.161290                  57.943853   \n",
       "\n",
       "   Ill250.alt_reason_alignmentScore  Ill250.alt_reason_insertSizeScore  \\\n",
       "0                               0.0                                0.0   \n",
       "1                              35.0                                9.0   \n",
       "2                              28.0                                3.0   \n",
       "\n",
       "   Ill250.alt_reason_orientation  Ill250.amb_alnScore_mean  \\\n",
       "0                            0.0                872.238636   \n",
       "1                            0.0                861.743750   \n",
       "2                            0.0                886.130045   \n",
       "\n",
       "   Ill250.amb_alnScore_std      ...        pacbio.ref_insertSize_mean  \\\n",
       "0               151.265870      ...                       10683.11594   \n",
       "1               161.249545      ...                           0.00000   \n",
       "2               129.576288      ...                       10714.20833   \n",
       "\n",
       "   pacbio.ref_insertSize_std  pacbio.ref_reason_alignmentScore  refN_cnt  \\\n",
       "0                5291.525830                              69.0       0.0   \n",
       "1                   0.000000                               0.0       0.0   \n",
       "2                3615.789459                              24.0       0.0   \n",
       "\n",
       "   refN_pct  segdup_cnt  segdup_pct       start  tandemrep_cnt  tandemrep_pct  \n",
       "0       0.0         0.0         0.0  66398770.0            6.0       0.097264  \n",
       "1       0.0         0.0         0.0  14189915.0            3.0       0.037082  \n",
       "2       0.0         0.0         0.0  20950622.0           10.0       0.076469  \n",
       "\n",
       "[3 rows x 176 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pd.DataFrame()\n",
    "X3 = X2\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order features\n",
    "X5 = X2.reindex_axis(sorted(X2.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_step'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_log = model.predict_log_proba(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ill250.alt_alnScore_mean</th>\n",
       "      <th>Ill250.alt_alnScore_std</th>\n",
       "      <th>Ill250.alt_count</th>\n",
       "      <th>Ill250.alt_insertSize_mean</th>\n",
       "      <th>Ill250.alt_insertSize_std</th>\n",
       "      <th>Ill250.alt_reason_alignmentScore</th>\n",
       "      <th>Ill250.alt_reason_insertSizeScore</th>\n",
       "      <th>Ill250.alt_reason_orientation</th>\n",
       "      <th>Ill250.amb_alnScore_mean</th>\n",
       "      <th>Ill250.amb_alnScore_std</th>\n",
       "      <th>...</th>\n",
       "      <th>pacbio.ref_insertSize_mean</th>\n",
       "      <th>pacbio.ref_insertSize_std</th>\n",
       "      <th>pacbio.ref_reason_alignmentScore</th>\n",
       "      <th>refN_cnt</th>\n",
       "      <th>refN_pct</th>\n",
       "      <th>segdup_cnt</th>\n",
       "      <th>segdup_pct</th>\n",
       "      <th>start</th>\n",
       "      <th>tandemrep_cnt</th>\n",
       "      <th>tandemrep_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Ill250.alt_alnScore_mean, Ill250.alt_alnScore_std, Ill250.alt_count, Ill250.alt_insertSize_mean, Ill250.alt_insertSize_std, Ill250.alt_reason_alignmentScore, Ill250.alt_reason_insertSizeScore, Ill250.alt_reason_orientation, Ill250.amb_alnScore_mean, Ill250.amb_alnScore_std, Ill250.amb_count, Ill250.amb_insertSize_mean, Ill250.amb_insertSize_std, Ill250.amb_reason_alignmentScore_alignmentScore, Ill250.amb_reason_alignmentScore_orientation, Ill250.amb_reason_flanking, Ill250.amb_reason_insertSizeScore_alignmentScore, Ill250.amb_reason_multimapping, Ill250.amb_reason_orientation_alignmentScore, Ill250.amb_reason_orientation_orientation, Ill250.amb_reason_same_scores, Ill250.ref_alnScore_mean, Ill250.ref_alnScore_std, Ill250.ref_count, Ill250.ref_insertSize_mean, Ill250.ref_insertSize_std, Ill250.ref_reason_alignmentScore, Ill250.ref_reason_orientation, Ill300x.alt_alnScore_mean, Ill300x.alt_alnScore_std, Ill300x.alt_count, Ill300x.alt_insertSize_mean, Ill300x.alt_insertSize_std, Ill300x.alt_reason_alignmentScore, Ill300x.alt_reason_insertSizeScore, Ill300x.alt_reason_orientation, Ill300x.amb_alnScore_mean, Ill300x.amb_alnScore_std, Ill300x.amb_count, Ill300x.amb_insertSize_mean, Ill300x.amb_insertSize_std, Ill300x.amb_reason_alignmentScore_alignmentScore, Ill300x.amb_reason_alignmentScore_insertSizeScore, Ill300x.amb_reason_alignmentScore_orientation, Ill300x.amb_reason_flanking, Ill300x.amb_reason_insertSizeScore_alignmentScore, Ill300x.amb_reason_insertSizeScore_insertSizeScore, Ill300x.amb_reason_multimapping, Ill300x.amb_reason_orientation_alignmentScore, Ill300x.amb_reason_orientation_orientation, Ill300x.amb_reason_same_scores, Ill300x.ref_alnScore_mean, Ill300x.ref_alnScore_std, Ill300x.ref_count, Ill300x.ref_insertSize_mean, Ill300x.ref_insertSize_std, Ill300x.ref_reason_alignmentScore, Ill300x.ref_reason_insertSizeScore, Ill300x.ref_reason_orientation, IllMP.alt_alnScore_mean, IllMP.alt_alnScore_std, IllMP.alt_count, IllMP.alt_insertSize_mean, IllMP.alt_insertSize_std, IllMP.alt_reason_alignmentScore, IllMP.alt_reason_insertSizeScore, IllMP.alt_reason_orientation, IllMP.amb_alnScore_mean, IllMP.amb_alnScore_std, IllMP.amb_count, IllMP.amb_insertSize_mean, IllMP.amb_insertSize_std, IllMP.amb_reason_alignmentScore_alignmentScore, IllMP.amb_reason_alignmentScore_orientation, IllMP.amb_reason_flanking, IllMP.amb_reason_insertSizeScore_alignmentScore, IllMP.amb_reason_insertSizeScore_insertSizeScore, IllMP.amb_reason_multimapping, IllMP.amb_reason_orientation_alignmentScore, IllMP.amb_reason_orientation_orientation, IllMP.amb_reason_same_scores, IllMP.ref_alnScore_mean, IllMP.ref_alnScore_std, IllMP.ref_count, IllMP.ref_insertSize_mean, IllMP.ref_insertSize_std, IllMP.ref_reason_alignmentScore, IllMP.ref_reason_insertSizeScore, IllMP.ref_reason_orientation, Size, TenX.HP1_alt_alnScore_mean, TenX.HP1_alt_alnScore_std, TenX.HP1_alt_count, TenX.HP1_alt_insertSize_mean, TenX.HP1_alt_insertSize_std, TenX.HP1_alt_reason_alignmentScore, TenX.HP1_alt_reason_insertSizeScore, TenX.HP1_alt_reason_orientation, TenX.HP1_amb_alnScore_mean, TenX.HP1_amb_alnScore_std, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 176 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['predicted_label'] = pred\n",
    "X5['chrom'] = df_['chrom']\n",
    "X5['GTcons'] = df_['GTcons']\n",
    "X5['start'] = df_['start']\n",
    "X5['end'] = df_['end']\n",
    "X5['Size'] = df_['Size']\n",
    "X5['GTsupp'] = df_['GTsupp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.concat([X5, pd.DataFrame(pred_prob, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7 = pd.concat([X5, pd.DataFrame(pred_prob_log, columns=['1','2','3'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X7.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49_log._predLrgcsv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6 = pd.read_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49_predLrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.rename(columns={'1': 'Homozygous_Reference_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'2': 'Heterozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'3': 'Homozygous_Variant_GTcons'}, inplace=True)\n",
    "X6.rename(columns={'predicted_label': 'predicted_GTcons_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace('Homozygous_Reference', '0', inplace=True)\n",
    "X6['GTcons'].replace('Heterozygous_Variant', '1', inplace=True)\n",
    "X6['GTcons'].replace('Homozygous_Variant', '2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6.to_csv('/Volumes/lesleydata/RF_model_trainingData_test/size_data/results/df_20to49_final_predLrg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X6['GTcons'].fillna(999)\n",
    "# X7 = X6[X6.GTcons != 999]\n",
    "# X6['predicted_GTcons_label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6['predicted_GTcons_label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.GTcons = X6.GTcons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    120\n",
      "1    100\n",
      "2     64\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (pd.value_counts(X6['GTcons'].values, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Label Analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "  * The [random forest(RF) model](#train_test) was trained on svanalyzer data. The trained model was used to predict consensus GT labels for the 5000 deletions that were randomly selected from the union_refalt vcf. The following is a comparison of model predicted labels [Conesus GT] to consensus genotype generated by the R script for the 5000 randomly selected datapoints from union_refalt.vcf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118   2   0]\n",
      " [  0 100   0]\n",
      " [  0   5  59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "consensus_GT = X6['GTcons']\n",
    "predict = X6['predicted_GTcons_label']\n",
    "print(confusion_matrix(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X6['GTcons'].replace(0, 'Homozygous_Reference', inplace=True)\n",
    "X6['GTcons'].replace(1, 'Heterozygous_Variant', inplace=True)\n",
    "X6['GTcons'].replace(2, 'Homozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(0.0, 'Homozygous_Reference', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(1.0, 'Heterozygous_Variant', inplace=True)\n",
    "X6['predicted_GTcons_label'].replace(2.0, 'Homozygous_Variant', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predict_precision_score_matrix'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of the prediction subset: 0.975\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of the prediction subset: {:.3f}'.format(precision_score(consensus_GT, predict, average='micro'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the prediction subset: 0.975\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the prediction subset: {:.3f}'.format(accuracy_score(consensus_GT, predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>59</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                   100                     0   \n",
       "Homozygous_Reference                     2                   118   \n",
       "Homozygous_Variant                       5                     0   \n",
       "All                                    107                   118   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0  100  \n",
       "Homozygous_Reference                   0  120  \n",
       "Homozygous_Variant                    59   64  \n",
       "All                                   59  284  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** High Confidence Label Analysis**\n",
    "* **Reminder:** The labels predicted by the model are the following consensus genotype:\n",
    "    * Homozygous Reference: 0 \n",
    "    * Heterozygous Variant: 1 \n",
    "    * Homozygous Variant: 2 \n",
    "* Here **high confidence labels** are the GTcons labels predicted by the model that were also assigned a predict probability of either 0.9 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_conf_labels = X6[(X6['Homozygous_Reference_GTcons'] == 1) | (X6['Homozygous_Reference_GTcons'] >= 0.9) | (X6['Heterozygous_Variant_GTcons'] == 1) | (X6['Heterozygous_Variant_GTcons'] >= 0.9) | (X6['Homozygous_Variant_GTcons'] == 1) | (X6['Homozygous_Variant_GTcons'] >= 0.9)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiconf_precision_score'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Heterozygous_Variant</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Reference</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homozygous_Variant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>33</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             Heterozygous_Variant  Homozygous_Reference  \\\n",
       "True                                                               \n",
       "Heterozygous_Variant                    49                     0   \n",
       "Homozygous_Reference                     0                    50   \n",
       "Homozygous_Variant                       0                     0   \n",
       "All                                     49                    50   \n",
       "\n",
       "Predicted             Homozygous_Variant  All  \n",
       "True                                           \n",
       "Heterozygous_Variant                   0   49  \n",
       "Homozygous_Reference                   0   50  \n",
       "Homozygous_Variant                    33   33  \n",
       "All                                   33  132  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_GT = high_conf_labels['GTcons']\n",
    "predict = high_conf_labels['predicted_GTcons_label']\n",
    "pd.crosstab(consensus_GT, predict, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Heterozygous_Variant       1.00      1.00      1.00        49\n",
      "Homozygous_Reference       1.00      1.00      1.00        50\n",
      "  Homozygous_Variant       1.00      1.00      1.00        33\n",
      "\n",
      "         avg / total       1.00      1.00      1.00       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(consensus_GT, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
